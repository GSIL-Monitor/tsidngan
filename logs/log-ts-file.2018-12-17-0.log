2018-12-17 10:20:14.045 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 10:20:14 CST 2018]; root of context hierarchy
2018-12-17 10:20:14.144 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 10:20:14.146 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 10:20:14.357 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 10:20:14.398 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$49e8501d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:15.813 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 10:20:15.838 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@70e13fa: startup date [Mon Dec 17 10:20:15 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 10:20:16.748 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 10:20:16.938 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 10:20:17.157 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 10:20:17.184 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 10:20:17.371 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$2dce4d20] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.581 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.584 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$86a08a77] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.598 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.608 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.617 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:17.640 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$49e8501d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 10:20:18.415 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 10:20:18.444 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 10:20:18.446 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 10:20:19.176 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 10:20:19.177 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3339 ms
2018-12-17 10:20:19.937 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 10:20:19.939 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 10:20:19.944 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 10:20:19.944 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 10:20:19.945 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 10:20:19.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 10:20:19.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 10:20:19.946 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 10:20:19.947 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 10:20:20.005 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 10:20:21.748 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 10:20:21.748 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 10:20:21.776 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 10:20:21.776 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 10:20:22.392 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@70e13fa: startup date [Mon Dec 17 10:20:15 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 10:20:22.485 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 10:20:22.486 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 10:20:22.486 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 10:20:22.487 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 10:20:22.487 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 10:20:22.487 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 10:20:22.488 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 10:20:22.490 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/uploadFile/{fileName}/{uploadFile}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.HdfsController.UploadFile(java.lang.String,java.lang.String) throws java.lang.Exception
2018-12-17 10:20:22.490 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 10:20:22.493 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 10:20:22.493 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 10:20:22.569 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 10:20:22.569 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 10:20:22.642 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 10:20:23.702 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@70e13fa: startup date [Mon Dec 17 10:20:15 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 10:20:23.704 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 10:20:23.740 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 10:20:24.986 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 10:20:25.220 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 10:20:25.221 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 10:20:25.228 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 10:20:25.230 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 10:20:25.231 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 10:20:25.234 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 10:20:25.262 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 10:20:25.280 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=70e13fa,type=ConfigurationPropertiesRebinder]
2018-12-17 10:20:25.288 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 10:20:25.487 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 10:20:25.509 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 10:20:25.607 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 10:20:25.608 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 10:20:25.634 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545013225634 with initial instances count: 0
2018-12-17 10:20:25.647 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 10:20:25.663 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 10:20:25.705 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 10:20:25.773 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 10:20:25.812 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 10:20:25.813 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 10:20:25.816 [main] INFO  cn.trasen.Application - Started Application in 13.465 seconds (JVM running for 14.803)
2018-12-17 10:23:10.812 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 10:23:10.812 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 10:23:10.855 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 43 ms
2018-12-17 10:23:10.893 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:23:10.925 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:23:10.926 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:null
2018-12-17 10:23:10.926 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:null
2018-12-17 10:23:11.314 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"token已失效，请重新登录！","code":"-1"}
2018-12-17 10:23:11.456 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - isAjaxReq: false
2018-12-17 10:23:11.456 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - http://39.104.149.133:8080/page/login?returnURL=http%3A%2F%2Flocalhost%3A6765%2Fts-file%2Fhdfs%2FuploadFile%2Ftest%2F1
2018-12-17 10:23:13.990 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:23:13.991 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:23:13.991 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:23:13.991 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:23:14.083 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:13:23","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"110.53.163.149","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"4a8b9e4a-166d-41ed-b2a0-a528cfe1c119","usericon":null,"token":"4a8b9e4a-166d-41ed-b2a0-a528cfe1c119","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:23:14.294 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:23:14.847 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 10:23:14.863 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 10:23:14.864 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-17 10:23:14.864 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
2018-12-17 10:23:14.864 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
2018-12-17 10:23:14.865 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2018-12-17 10:23:14.933 [http-nio-6765-exec-2] DEBUG o.a.h.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2018-12-17 10:23:14.936 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:23:15.027 [http-nio-6765-exec-2] DEBUG org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
2018-12-17 10:23:15.073 [http-nio-6765-exec-2] DEBUG org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
2018-12-17 10:23:15.075 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
2018-12-17 10:23:15.357 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.371 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.374 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.377 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.379 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.380 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 10:23:15.414 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 10:23:15.682 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 10:23:15.685 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 10:23:15.709 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 10:23:15.711 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 10:23:15.711 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:23:15.711 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:23:15.736 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:23:15.737 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:23:15.871 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:23:15.872 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:23:15.872 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:23:15.872 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:23:15.907 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:23:15.930 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
2018-12-17 10:23:15.938 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:23:15.979 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2018-12-17 10:23:15.983 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2018-12-17 10:23:16.083 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2018-12-17 10:23:16.084 [http-nio-6765-exec-2] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2018-12-17 10:23:16.084 [http-nio-6765-exec-2] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-17 10:23:16.191 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-17 10:23:16.305 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@65acb6d9
2018-12-17 10:23:16.329 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:23:17.134 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-17 10:23:17.140 [http-nio-6765-exec-2] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:23:37.549 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:23:37.592 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:24:09.098 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 0 time(s); maxRetries=45
2018-12-17 10:24:29.111 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 1 time(s); maxRetries=45
2018-12-17 10:24:49.120 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 2 time(s); maxRetries=45
2018-12-17 10:25:09.128 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 3 time(s); maxRetries=45
2018-12-17 10:25:29.139 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 4 time(s); maxRetries=45
2018-12-17 10:25:49.148 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 5 time(s); maxRetries=45
2018-12-17 10:26:09.157 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 6 time(s); maxRetries=45
2018-12-17 10:26:29.167 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 7 time(s); maxRetries=45
2018-12-17 10:26:49.175 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 8 time(s); maxRetries=45
2018-12-17 10:27:09.183 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 9 time(s); maxRetries=45
2018-12-17 10:27:29.193 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 10 time(s); maxRetries=45
2018-12-17 10:27:49.205 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 11 time(s); maxRetries=45
2018-12-17 10:28:09.222 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 12 time(s); maxRetries=45
2018-12-17 10:28:29.232 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 13 time(s); maxRetries=45
2018-12-17 10:28:49.241 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 14 time(s); maxRetries=45
2018-12-17 10:29:09.250 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 15 time(s); maxRetries=45
2018-12-17 10:29:29.259 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 16 time(s); maxRetries=45
2018-12-17 10:29:49.275 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 17 time(s); maxRetries=45
2018-12-17 10:30:09.286 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 18 time(s); maxRetries=45
2018-12-17 10:30:29.294 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 19 time(s); maxRetries=45
2018-12-17 10:30:49.303 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 20 time(s); maxRetries=45
2018-12-17 10:31:09.312 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 21 time(s); maxRetries=45
2018-12-17 10:31:29.321 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 22 time(s); maxRetries=45
2018-12-17 10:31:49.331 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 23 time(s); maxRetries=45
2018-12-17 10:32:09.342 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 24 time(s); maxRetries=45
2018-12-17 10:32:29.353 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 25 time(s); maxRetries=45
2018-12-17 10:32:49.361 [http-nio-6765-exec-2] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 192.168.2.199/192.168.2.199:8020. Already tried 26 time(s); maxRetries=45
2018-12-17 10:32:58.688 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:32:58.713 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations
2018-12-17 10:32:58.871 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #0
2018-12-17 10:32:59.125 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #0 ClientNamenodeProtocolTranslatorPB.getBlockLocations over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: File does not exist: /usr/hadoop/hadoop-2.9.1/etc/hadoop/core-site.xml
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:150)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:709)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:330)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:289)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:274)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:332)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:329)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:329)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:112)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:33:08.688 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:33:08.688 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:35:01.726 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:35:01.727 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:35:01.727 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:35:01.727 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:35:01.837 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:35:01.840 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:35:05.284 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:35:05.292 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:35:05.296 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:35:05.299 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:35:05.303 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:35:05.313 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:35:05.316 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:35:05.319 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:35:05.323 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:35:05.331 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:35:05.341 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:35:05.347 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:35:05.354 [http-nio-6765-exec-8] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:36:47.199 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:36:47.199 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:36:47.203 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:36:47.203 [IPC Parameter Sending Thread #1] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations
2018-12-17 10:36:47.206 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #1
2018-12-17 10:36:47.207 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #1 ClientNamenodeProtocolTranslatorPB.getBlockLocations over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: File does not exist: /usr/hadoop/hadoop-2.9.1/etc/hadoop/core-site.xml
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:72)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:62)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:150)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1825)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:709)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:381)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:330)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:289)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:274)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:332)
	at org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:329)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:329)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:914)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:114)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:36:57.204 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:36:57.204 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:43:32.992 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:43:32.993 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:43:32.994 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:43:32.994 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:43:33.078 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:43:33.082 [http-nio-6765-exec-6] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:43:36.618 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:43:36.625 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:43:36.629 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:43:36.633 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:43:36.637 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:43:36.646 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:43:36.650 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:43:36.654 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:43:36.657 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:43:36.665 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:43:36.675 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:43:36.681 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:43:36.687 [http-nio-6765-exec-6] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:43:40.701 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2018-12-17 10:43:40.711 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2018-12-17 10:43:40.717 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - Using user: "root" with name root
2018-12-17 10:43:40.721 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - User entry: "root"
2018-12-17 10:43:40.725 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - Assuming keytab is managed externally since logged in from subject.
2018-12-17 10:43:40.731 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:root (auth:SIMPLE)
2018-12-17 10:43:40.734 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
2018-12-17 10:43:40.739 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
2018-12-17 10:43:40.742 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:43:40.745 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
2018-12-17 10:43:40.901 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:43:40.905 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:43:40.913 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:43:40.918 [IPC Parameter Sending Thread #2] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 10:43:40.927 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #2
2018-12-17 10:43:40.927 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 28ms
2018-12-17 10:43:41.590 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.hdfs.DFSClient - /usr/hadoop/text.txt: masked=rw-r--r--
2018-12-17 10:43:42.409 [IPC Parameter Sending Thread #2] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #3 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 10:43:42.420 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #3
2018-12-17 10:43:42.502 [http-nio-6765-exec-6] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #3 ClientNamenodeProtocolTranslatorPB.create over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoop, access=WRITE, inode="/":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:350)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1751)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1735)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1694)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.resolvePathForStartFile(FSDirWriteFileOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2280)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2224)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:745)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:267)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1206)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1148)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:480)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:477)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:477)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:418)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:43:52.407 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:43:52.407 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:49:06.006 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:49:06.007 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:49:06.007 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:49:06.007 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:49:06.098 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:49:06.101 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:49:10.278 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:49:10.284 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:49:10.288 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:49:10.291 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:49:10.295 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:49:10.305 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:49:10.308 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:49:10.312 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:49:10.315 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:49:10.322 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:49:10.332 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:49:10.338 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:49:10.344 [http-nio-6765-exec-4] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:49:22.755 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:49:22.763 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:49:22.767 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:49:22.770 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:49:22.774 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:49:22.783 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:49:22.787 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:49:22.792 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:49:22.796 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:49:22.802 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:49:22.813 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:49:22.818 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:49:22.825 [http-nio-6765-exec-4] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:49:24.877 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:49:24.883 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:49:24.890 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:49:24.895 [IPC Parameter Sending Thread #3] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #4 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 10:49:24.900 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #4
2018-12-17 10:49:24.901 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 24ms
2018-12-17 10:49:24.934 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - /text.txt: masked=rw-r--r--
2018-12-17 10:49:24.942 [IPC Parameter Sending Thread #3] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #5 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 10:49:24.945 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #5
2018-12-17 10:49:24.953 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #5 ClientNamenodeProtocolTranslatorPB.create over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoop, access=WRITE, inode="/":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:350)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1751)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1735)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1694)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.resolvePathForStartFile(FSDirWriteFileOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2280)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2224)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:745)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:267)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1206)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1148)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:480)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:477)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:477)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:418)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:49:34.941 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:49:34.941 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:52:01.295 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:52:01.295 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:52:01.295 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:01.295 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:01.376 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:52:01.378 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:52:01.396 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:52:01.396 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:52:01.397 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:52:01.397 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:52:01.397 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:52:01.398 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:52:01.399 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:52:01.399 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:52:01.399 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:52:01.399 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:52:01.400 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:52:01.400 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:52:01.400 [http-nio-6765-exec-9] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:52:01.401 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:52:01.401 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:52:01.403 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:52:01.405 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #6 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 10:52:01.407 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #6
2018-12-17 10:52:01.407 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 6ms
2018-12-17 10:52:01.408 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/root/text.txt: masked=rw-r--r--
2018-12-17 10:52:01.409 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #7 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 10:52:01.411 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #7
2018-12-17 10:52:01.412 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #7 ClientNamenodeProtocolTranslatorPB.create over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoop, access=WRITE, inode="/user":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:350)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1751)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1735)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1694)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.resolvePathForStartFile(FSDirWriteFileOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2280)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2224)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:745)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:267)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1206)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1148)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:480)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:477)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:477)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:418)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:52:06.492 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:52:06.493 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:52:06.493 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:06.493 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:06.593 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:52:06.595 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:52:09.795 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:52:09.802 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:52:09.806 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:52:09.810 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:52:09.813 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:52:09.823 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:52:09.827 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:52:09.830 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:52:09.834 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:52:09.840 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:52:09.850 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:52:09.856 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:52:09.863 [http-nio-6765-exec-5] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:52:11.362 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:52:11.367 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:52:11.375 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 2
2018-12-17 10:52:11.378 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #8 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 10:52:11.380 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #8
2018-12-17 10:52:11.381 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 20ms
2018-12-17 10:52:11.408 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:52:11.408 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 1
2018-12-17 10:52:11.413 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/root/text.txt: masked=rw-r--r--
2018-12-17 10:52:11.423 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #9 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 10:52:11.426 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #9
2018-12-17 10:52:11.434 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.io.retry.RetryInvocationHandler - Exception while invoking call #9 ClientNamenodeProtocolTranslatorPB.create over null. Not retrying because try once and fail.
org.apache.hadoop.ipc.RemoteException: Permission denied: user=hadoop, access=WRITE, inode="/user":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:350)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:251)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:189)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1751)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1735)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1694)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.resolvePathForStartFile(FSDirWriteFileOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2280)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2224)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:745)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:871)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:817)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1889)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2606)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy149.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:297)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy150.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:267)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1206)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1148)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:480)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:477)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:477)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:418)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1067)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1048)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:937)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 10:52:21.421 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:52:21.421 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:52:24.630 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 10:52:24.630 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 10:52:24.631 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:24.631 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 10:52:24.713 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 10:52:24.718 [http-nio-6765-exec-7] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 10:52:30.051 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 10:52:30.058 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 10:52:30.061 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 10:52:30.065 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 10:52:30.068 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 10:52:30.078 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 10:52:30.081 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 10:52:30.085 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 10:52:30.089 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 10:52:30.096 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 10:52:30.105 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 10:52:30.130 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:52:30.137 [http-nio-6765-exec-7] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 10:52:31.073 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 10:52:31.078 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 10:52:31.086 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 10:52:31.089 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #10 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 10:52:31.091 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #10
2018-12-17 10:52:31.091 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 20ms
2018-12-17 10:52:31.120 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 10:52:31.128 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #11 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 10:52:31.160 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #11
2018-12-17 10:52:31.161 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 36ms
2018-12-17 10:52:31.465 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 10:52:31.676 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_2087225887_33] with renew id 1 started
2018-12-17 10:52:31.719 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.hdfs.DataStreamer - Waiting for ack for: -1
2018-12-17 10:52:31.749 [IPC Parameter Sending Thread #4] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #12 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
2018-12-17 10:52:31.756 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #12
2018-12-17 10:52:31.756 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 9ms
2018-12-17 10:52:39.516 [http-nio-6765-exec-7] DEBUG org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 10:52:41.748 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 10:52:41.748 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 10:53:01.690 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 10:53:31.703 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 10:53:32.704 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 10:53:32.704 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:07:19.346 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:07:19.347 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 11:07:19.347 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:07:19.347 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:07:19.452 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:07:19.455 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:07:19.474 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:07:19.475 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:07:19.475 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:07:19.475 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:07:19.475 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:07:19.476 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 11:07:19.477 [http-nio-6765-exec-1] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:07:19.478 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:07:19.478 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:07:19.485 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:07:19.486 [IPC Parameter Sending Thread #5] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #13 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:07:19.492 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #13
2018-12-17 11:07:19.492 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 14ms
2018-12-17 11:07:19.493 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:07:19.493 [IPC Parameter Sending Thread #5] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #14 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:07:19.506 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #14
2018-12-17 11:07:19.506 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 13ms
2018-12-17 11:07:19.506 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:07:19.509 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-1077707161_27] with renew id 1 started
2018-12-17 11:07:19.535 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSOutputStream - Closing an already closed stream. [Stream:true, streamer:true]
2018-12-17 11:07:19.574 [http-nio-6765-exec-1] ERROR o.a.c.c.C.[.[.[/ts-file].[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [/ts-file] threw exception [Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V] with root cause
java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V
	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(Native Method)
	at org.apache.hadoop.util.NativeCrc32.calculateChunkedSumsByteArray(NativeCrc32.java:86)
	at org.apache.hadoop.util.DataChecksum.calculateChunkedSums(DataChecksum.java:463)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:207)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:848)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:818)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:69)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:128)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 11:07:19.672 [http-nio-6765-exec-1] DEBUG freemarker.cache - Couldn't find template in cache for "error.ftl"("zh_CN", UTF-8, parsed); will try to load it.
2018-12-17 11:07:19.686 [http-nio-6765-exec-1] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh_CN.ftl"): Not found
2018-12-17 11:07:19.689 [http-nio-6765-exec-1] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh.ftl"): Not found
2018-12-17 11:07:19.690 [http-nio-6765-exec-1] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error.ftl"): Not found
2018-12-17 11:07:29.493 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:07:29.493 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:07:49.523 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:08:19.538 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:08:19.538 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:08:19.538 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:08:35.387 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:08:35.387 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 11:08:35.387 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:08:35.388 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:08:35.483 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:08:35.491 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:08:35.518 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:08:35.518 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:08:35.518 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:08:35.518 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:08:35.518 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 11:08:35.521 [http-nio-6765-exec-2] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:08:35.522 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:08:35.522 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:08:35.527 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:08:35.528 [IPC Parameter Sending Thread #6] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #15 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:08:35.533 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #15
2018-12-17 11:08:35.533 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 11ms
2018-12-17 11:08:35.534 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:08:35.535 [IPC Parameter Sending Thread #6] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #16 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:08:35.541 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #16
2018-12-17 11:08:35.541 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 7ms
2018-12-17 11:08:35.542 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:08:35.554 [http-nio-6765-exec-2] DEBUG org.apache.hadoop.hdfs.DFSOutputStream - Closing an already closed stream. [Stream:true, streamer:true]
2018-12-17 11:08:35.557 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 started
2018-12-17 11:08:35.564 [http-nio-6765-exec-2] ERROR o.a.c.c.C.[.[.[/ts-file].[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [/ts-file] threw exception [Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V] with root cause
java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V
	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(Native Method)
	at org.apache.hadoop.util.NativeCrc32.calculateChunkedSumsByteArray(NativeCrc32.java:86)
	at org.apache.hadoop.util.DataChecksum.calculateChunkedSums(DataChecksum.java:463)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:207)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:848)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:818)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:69)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:128)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 11:08:35.574 [http-nio-6765-exec-2] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh_CN.ftl"): Not found
2018-12-17 11:08:35.575 [http-nio-6765-exec-2] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh.ftl"): Not found
2018-12-17 11:08:35.575 [http-nio-6765-exec-2] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error.ftl"): Not found
2018-12-17 11:08:35.575 [http-nio-6765-exec-2] DEBUG freemarker.cache - "error.ftl"("zh_CN", UTF-8, parsed) no source found.
2018-12-17 11:08:45.536 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:08:45.536 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:08:50.699 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:08:50.699 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 11:08:50.699 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:08:50.699 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:08:50.792 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:08:50.794 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:08:50.805 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:08:50.805 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:08:50.805 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:08:50.805 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 11:08:50.806 [http-nio-6765-exec-9] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:08:53.129 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:08:53.134 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:08:53.142 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:08:53.144 [IPC Parameter Sending Thread #6] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #17 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:08:53.146 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #17
2018-12-17 11:08:53.147 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 20ms
2018-12-17 11:08:53.187 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:08:53.194 [IPC Parameter Sending Thread #6] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #18 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:08:53.197 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #18
2018-12-17 11:08:53.198 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 6ms
2018-12-17 11:08:53.205 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:08:53.213 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-149033171_35] with renew id 1 started
2018-12-17 11:08:53.223 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSOutputStream - Closing an already closed stream. [Stream:true, streamer:true]
2018-12-17 11:08:59.669 [http-nio-6765-exec-9] ERROR o.a.c.c.C.[.[.[/ts-file].[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [/ts-file] threw exception [Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V] with root cause
java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V
	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(Native Method)
	at org.apache.hadoop.util.NativeCrc32.calculateChunkedSumsByteArray(NativeCrc32.java:86)
	at org.apache.hadoop.util.DataChecksum.calculateChunkedSums(DataChecksum.java:463)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:207)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:848)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:818)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:69)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:128)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 11:08:59.678 [http-nio-6765-exec-9] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh_CN.ftl"): Not found
2018-12-17 11:08:59.680 [http-nio-6765-exec-9] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh.ftl"): Not found
2018-12-17 11:08:59.681 [http-nio-6765-exec-9] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error.ftl"): Not found
2018-12-17 11:08:59.682 [http-nio-6765-exec-9] DEBUG freemarker.cache - "error.ftl"("zh_CN", UTF-8, parsed) no source found.
2018-12-17 11:09:03.192 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:09:03.192 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:09:05.575 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:09:23.229 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:09:35.587 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:09:35.587 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:09:35.587 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:09:53.241 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:09:53.241 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:09:53.241 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:14:18.624 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:14:18.624 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D030C757A75E6CBE7F2B911444B02D07
2018-12-17 11:14:18.625 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:14:18.625 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:14:18.726 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:14:18.729 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:14:18.741 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:14:18.742 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4ddb738f
2018-12-17 11:14:18.743 [http-nio-6765-exec-8] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:14:18.744 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:14:18.744 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:14:18.745 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:14:18.746 [IPC Parameter Sending Thread #7] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #19 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:14:18.749 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #19
2018-12-17 11:14:18.750 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 7ms
2018-12-17 11:14:18.751 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:14:18.751 [IPC Parameter Sending Thread #7] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop sending #20 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:14:18.757 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop got value #20
2018-12-17 11:14:18.757 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 6ms
2018-12-17 11:14:18.758 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:14:18.759 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 started
2018-12-17 11:14:18.761 [http-nio-6765-exec-8] DEBUG org.apache.hadoop.hdfs.DFSOutputStream - Closing an already closed stream. [Stream:true, streamer:true]
2018-12-17 11:14:18.766 [http-nio-6765-exec-8] ERROR o.a.c.c.C.[.[.[/ts-file].[dispatcherServlet] - Servlet.service() for servlet [dispatcherServlet] in context with path [/ts-file] threw exception [Handler dispatch failed; nested exception is java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V] with root cause
java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(II[BI[BIILjava/lang/String;JZ)V
	at org.apache.hadoop.util.NativeCrc32.nativeComputeChunkedSumsByteArray(Native Method)
	at org.apache.hadoop.util.NativeCrc32.calculateChunkedSumsByteArray(NativeCrc32.java:86)
	at org.apache.hadoop.util.DataChecksum.calculateChunkedSums(DataChecksum.java:463)
	at org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:207)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:164)
	at org.apache.hadoop.fs.FSOutputSummer.flushBuffer(FSOutputSummer.java:145)
	at org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:848)
	at org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:818)
	at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:72)
	at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:69)
	at org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:128)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:392)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:364)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2310)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2276)
	at cn.trasen.tsfile.utils.HdfsUtils.uploadFile(HdfsUtils.java:107)
	at cn.trasen.tsfile.utils.HdfsUtils$$FastClassBySpringCGLIB$$ffe2624a.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.utils.HdfsUtils$$EnhancerBySpringCGLIB$$dc9efc3f.uploadFile(<generated>)
	at cn.trasen.tsfile.controller.HdfsController.UploadFile(HdfsController.java:21)
	at cn.trasen.tsfile.controller.HdfsController$$FastClassBySpringCGLIB$$f8f72136.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.controller.HdfsController$$EnhancerBySpringCGLIB$$9725ec83.UploadFile(<generated>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:635)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at cn.trasen.BootComm.filter.SSOFilter.doFilter(SSOFilter.java:199)
	at cn.trasen.BootComm.filter.SSOFilter$$FastClassBySpringCGLIB$$4fe38d4f.invoke(<generated>)
	at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)
	at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)
	at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)
	at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)
	at cn.trasen.tsfile.filter.LoginFilter$$EnhancerBySpringCGLIB$$3e611198.doFilter(<generated>)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at com.alibaba.druid.support.http.WebStatFilter.doFilter(WebStatFilter.java:123)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:108)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:748)
2018-12-17 11:14:18.773 [http-nio-6765-exec-8] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh_CN.ftl"): Not found
2018-12-17 11:14:18.774 [http-nio-6765-exec-8] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error_zh.ftl"): Not found
2018-12-17 11:14:18.774 [http-nio-6765-exec-8] DEBUG freemarker.cache - TemplateLoader.findTemplateSource("error.ftl"): Not found
2018-12-17 11:14:18.774 [http-nio-6765-exec-8] DEBUG freemarker.cache - "error.ftl"("zh_CN", UTF-8, parsed) no source found.
2018-12-17 11:14:28.752 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:14:28.752 [IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (249511760) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:14:48.776 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:15:18.786 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:15:18.786 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:15:18.786 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:42:59.861 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 11:42:59 CST 2018]; root of context hierarchy
2018-12-17 11:43:00.031 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 11:43:00.033 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 11:43:00.209 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 11:43:00.260 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$37fc6e78] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:01.704 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 11:43:01.732 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6d5037a9: startup date [Mon Dec 17 11:43:01 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 11:43:03.133 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 11:43:03.356 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 11:43:03.629 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 11:43:03.662 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 11:43:03.879 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$1be26b7b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.124 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.127 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$74b4a8d2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.143 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.156 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.163 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.191 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$37fc6e78] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 11:43:04.888 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 11:43:04.909 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 11:43:04.911 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 11:43:05.168 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 11:43:05.168 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3436 ms
2018-12-17 11:43:05.744 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 11:43:05.746 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 11:43:05.751 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 11:43:05.752 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 11:43:05.753 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 11:43:05.753 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 11:43:05.753 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 11:43:05.753 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 11:43:05.753 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 11:43:05.816 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 11:43:07.328 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 11:43:07.328 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 11:43:07.367 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 11:43:07.367 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 11:43:07.795 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6d5037a9: startup date [Mon Dec 17 11:43:01 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 11:43:07.913 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 11:43:07.915 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 11:43:07.916 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 11:43:07.916 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 11:43:07.917 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 11:43:07.917 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 11:43:07.918 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 11:43:07.920 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 11:43:07.920 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/uploadFile/{fileName}/{uploadFile}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.HdfsController.UploadFile(java.lang.String,java.lang.String) throws java.lang.Exception
2018-12-17 11:43:07.925 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 11:43:07.926 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 11:43:08.007 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 11:43:08.007 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 11:43:08.070 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 11:43:09.061 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@6d5037a9: startup date [Mon Dec 17 11:43:01 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 11:43:09.063 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 11:43:09.099 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 11:43:09.899 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 11:43:10.131 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 11:43:10.134 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 11:43:10.143 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 11:43:10.144 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 11:43:10.145 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 11:43:10.148 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 11:43:10.162 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 11:43:10.179 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=6d5037a9,type=ConfigurationPropertiesRebinder]
2018-12-17 11:43:10.194 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 11:43:10.456 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 11:43:10.466 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 11:43:10.551 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 11:43:10.551 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 11:43:10.578 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545018190578 with initial instances count: 0
2018-12-17 11:43:10.592 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 11:43:10.608 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 11:43:10.635 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 11:43:10.680 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 11:43:10.753 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 11:43:10.754 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 11:43:10.758 [main] INFO  cn.trasen.Application - Started Application in 12.597 seconds (JVM running for 13.707)
2018-12-17 11:43:50.226 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 11:43:50.226 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 11:43:50.257 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 31 ms
2018-12-17 11:43:50.297 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:43:50.330 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:11954760293ACEFA675E679FF58DC3EF
2018-12-17 11:43:50.331 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:43:50.331 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:43:50.548 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:43:50.759 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:43:51.134 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 11:43:51.153 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 11:43:51.154 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-17 11:43:51.154 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
2018-12-17 11:43:51.154 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
2018-12-17 11:43:51.155 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2018-12-17 11:43:51.215 [http-nio-6765-exec-1] DEBUG o.a.h.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2018-12-17 11:43:51.221 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:43:51.280 [http-nio-6765-exec-1] DEBUG org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
2018-12-17 11:43:51.333 [http-nio-6765-exec-1] DEBUG org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
2018-12-17 11:43:51.335 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
2018-12-17 11:43:51.535 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.541 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.545 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.547 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.549 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.550 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 11:43:51.587 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 11:43:51.815 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 11:43:51.816 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 11:43:51.829 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 11:43:51.829 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 11:43:51.830 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:43:51.830 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:43:51.843 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:43:51.843 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:43:51.936 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:43:51.936 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:43:51.936 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:43:51.936 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:43:51.947 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:43:51.966 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
2018-12-17 11:43:51.976 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:43:52.004 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2018-12-17 11:43:52.008 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2018-12-17 11:43:52.075 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2018-12-17 11:43:52.076 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2018-12-17 11:43:52.076 [http-nio-6765-exec-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-17 11:43:52.129 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-17 11:43:52.161 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@4365d51
2018-12-17 11:43:52.200 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@7e4ef376
2018-12-17 11:43:52.693 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-17 11:43:52.701 [http-nio-6765-exec-1] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:43:52.725 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
2018-12-17 11:43:52.725 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
2018-12-17 11:43:52.725 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - Using user: "root" with name root
2018-12-17 11:43:52.725 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - User entry: "root"
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - Assuming keytab is managed externally since logged in from subject.
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:root (auth:SIMPLE)
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting file
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.file.impl
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:43:52.726 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for file is class org.apache.hadoop.fs.LocalFileSystem
2018-12-17 11:43:52.776 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:43:52.779 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:43:52.792 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:43:52.796 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:43:52.810 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #0
2018-12-17 11:43:52.810 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 57ms
2018-12-17 11:43:52.843 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:43:52.866 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:43:52.876 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #1
2018-12-17 11:43:52.876 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 10ms
2018-12-17 11:43:52.896 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:43:52.910 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/user/hadoop/text.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
2018-12-17 11:43:52.910 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 0
2018-12-17 11:43:52.910 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 1
2018-12-17 11:43:52.910 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DataStreamer - Waiting for ack for: 1
2018-12-17 11:43:52.911 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Allocating new block
2018-12-17 11:43:52.913 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1694304849_27] with renew id 1 started
2018-12-17 11:43:52.946 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock
2018-12-17 11:43:52.976 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #2
2018-12-17 11:43:52.976 [Thread-11] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 30ms
2018-12-17 11:43:52.989 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - pipeline = [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]]
2018-12-17 11:43:52.989 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Connecting to datanode 192.168.2.199:50010
2018-12-17 11:43:52.990 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Send buf size 65536
2018-12-17 11:43:52.991 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #3 org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults
2018-12-17 11:43:53.021 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #3
2018-12-17 11:43:53.021 [Thread-11] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 31ms
2018-12-17 11:43:53.028 [Thread-11] DEBUG o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /192.168.2.199, datanodeId = DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]
2018-12-17 11:43:53.178 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - nodes [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]] storageTypes [DISK] storageIDs [DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c]
2018-12-17 11:43:53.180 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 72
2018-12-17 11:43:53.203 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 11:43:53.300 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001 sending packet packet seqno: 1 offsetInBlock: 72 lastPacketInBlock: true lastByteOffsetInBlock: 72
2018-12-17 11:43:53.305 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 11:43:53.306 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001] DEBUG org.apache.hadoop.hdfs.DataStreamer - Closing old block BP-776011292-192.168.5.199-1544757847053:blk_1073741825_1001
2018-12-17 11:43:53.309 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #4 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
2018-12-17 11:43:53.342 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #4
2018-12-17 11:43:53.342 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 33ms
2018-12-17 11:43:53.344 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@7e4ef376
2018-12-17 11:43:53.344 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@7e4ef376
2018-12-17 11:43:53.345 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7e4ef376
2018-12-17 11:43:53.345 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - Stopping client
2018-12-17 11:43:53.345 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:43:53.345 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:44:22.927 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:44:52.938 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:44:53.940 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:44:53.940 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 11:44:54.767 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:44:54.767 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:11954760293ACEFA675E679FF58DC3EF
2018-12-17 11:44:54.767 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:44:54.767 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:44:54.860 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:44:54.864 [http-nio-6765-exec-4] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:44:54.882 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:44:54.887 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:44:54.888 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:44:54.888 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:44:54.888 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:44:54.889 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:44:54.891 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:44:54.891 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:44:54.891 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:44:54.891 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:44:54.891 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:44:54.892 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@235bd6b6
2018-12-17 11:44:54.892 [http-nio-6765-exec-4] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:44:54.893 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:44:54.894 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:44:54.903 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:44:54.904 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #5 org.apache.hadoop.hdfs.protocol.ClientProtocol.getFileInfo
2018-12-17 11:44:54.908 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #5
2018-12-17 11:44:54.908 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 15ms
2018-12-17 11:44:54.909 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/text.txt: masked=rw-r--r--
2018-12-17 11:44:54.910 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #6 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 11:44:54.933 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #6
2018-12-17 11:44:54.934 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 25ms
2018-12-17 11:44:54.934 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/text.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 11:44:54.939 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_2021187904_30] with renew id 1 started
2018-12-17 11:44:54.939 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/user/hadoop/text.txt, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
2018-12-17 11:44:54.939 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 0
2018-12-17 11:44:54.939 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 1
2018-12-17 11:44:54.939 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.hdfs.DataStreamer - Waiting for ack for: 1
2018-12-17 11:44:54.939 [Thread-15] DEBUG org.apache.hadoop.hdfs.DataStreamer - Allocating new block
2018-12-17 11:44:54.940 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #7 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock
2018-12-17 11:44:54.945 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #7
2018-12-17 11:44:54.945 [Thread-15] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 5ms
2018-12-17 11:44:54.945 [Thread-15] DEBUG org.apache.hadoop.hdfs.DataStreamer - pipeline = [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]]
2018-12-17 11:44:54.945 [Thread-15] DEBUG org.apache.hadoop.hdfs.DataStreamer - Connecting to datanode 192.168.2.199:50010
2018-12-17 11:44:54.947 [Thread-15] DEBUG org.apache.hadoop.hdfs.DataStreamer - Send buf size 65536
2018-12-17 11:44:54.947 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #8 org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults
2018-12-17 11:44:54.948 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #8
2018-12-17 11:44:54.949 [Thread-15] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 2ms
2018-12-17 11:44:54.949 [Thread-15] DEBUG o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /192.168.2.199, datanodeId = DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]
2018-12-17 11:44:54.963 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - nodes [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]] storageTypes [DISK] storageIDs [DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c]
2018-12-17 11:44:54.964 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 72
2018-12-17 11:44:54.966 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 11:44:54.967 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002 sending packet packet seqno: 1 offsetInBlock: 72 lastPacketInBlock: true lastByteOffsetInBlock: 72
2018-12-17 11:44:54.969 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 11:44:54.970 [DataStreamer for file /user/hadoop/text.txt block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002] DEBUG org.apache.hadoop.hdfs.DataStreamer - Closing old block BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002
2018-12-17 11:44:54.978 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #9 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
2018-12-17 11:44:54.984 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #9
2018-12-17 11:44:54.984 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 6ms
2018-12-17 11:44:54.984 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@235bd6b6
2018-12-17 11:44:54.985 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@235bd6b6
2018-12-17 11:44:54.985 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@235bd6b6
2018-12-17 11:44:54.985 [http-nio-6765-exec-4] DEBUG org.apache.hadoop.ipc.Client - Stopping client
2018-12-17 11:44:54.985 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:44:54.985 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:45:07.144 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 11:45:07.144 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:11954760293ACEFA675E679FF58DC3EF
2018-12-17 11:45:07.144 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost:6765/ts-file/hdfs/uploadFile/test/1 token:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:45:07.144 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:99eaff93-5094-45c5-8b09-e7d67ab85751
2018-12-17 11:45:07.239 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:8cfd93323a61765ab9b3eeb3213f1af1:0a54a36428897fd0f85e4bb2967219ef","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 10:23:14","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"99eaff93-5094-45c5-8b09-e7d67ab85751","usericon":null,"token":"99eaff93-5094-45c5-8b09-e7d67ab85751","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-WTX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-WTX","hospName":"深圳市网通兴","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 11:45:07.242 [http-nio-6765-exec-5] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 11:45:07.257 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 11:45:07.258 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 11:45:07.259 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 11:45:07.259 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@ecb5305
2018-12-17 11:45:07.259 [http-nio-6765-exec-5] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 11:45:20.442 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 11:45:20.449 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 11:45:20.462 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 11:45:20.472 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #10 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations
2018-12-17 11:45:20.486 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #10
2018-12-17 11:45:20.487 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getBlockLocations took 47ms
2018-12-17 11:45:20.554 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.DFSClient - newInfo = LocatedBlocks{
  fileLength=72
  underConstruction=false
  blocks=[LocatedBlock{BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002; getBlockSize()=72; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]]}]
  lastLocatedBlock=LocatedBlock{BP-776011292-192.168.5.199-1544757847053:blk_1073741826_1002; getBlockSize()=72; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]]}
  isLastBlockComplete=true}
2018-12-17 11:45:23.030 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 192.168.2.199:50010
2018-12-17 11:45:23.301 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop sending #11 org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults
2018-12-17 11:45:23.302 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop got value #11
2018-12-17 11:45:23.303 [http-nio-6765-exec-5] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 3ms
2018-12-17 11:45:23.308 [http-nio-6765-exec-5] DEBUG o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /192.168.2.199, datanodeId = DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]
2018-12-17 11:45:24.952 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:45:33.300 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 11:45:33.300 [IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (1859048547) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 11:45:54.989 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 11:45:54.989 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 11:45:54.989 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
2018-12-17 16:04:40.257 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 16:04:40 CST 2018]; root of context hierarchy
2018-12-17 16:04:40.411 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 16:04:40.415 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 16:04:40.603 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:04:40.660 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6637ff2a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:42.069 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 16:04:42.095 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d654825: startup date [Mon Dec 17 16:04:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:04:43.267 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 16:04:43.460 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 16:04:43.684 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 16:04:43.716 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:04:43.916 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$4a1dfc2d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.207 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.219 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$a2f03984] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.254 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.281 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.297 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:44.375 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$6637ff2a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:04:45.023 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 16:04:45.038 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 16:04:45.041 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 16:04:45.245 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 16:04:45.246 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3151 ms
2018-12-17 16:04:45.742 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 16:04:45.745 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 16:04:45.754 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 16:04:45.754 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 16:04:45.754 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 16:04:45.755 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 16:04:45.756 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 16:04:45.756 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 16:04:45.757 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 16:04:45.790 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 16:04:46.688 [main] WARN  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - Autowired annotation is not supported on static fields: private static java.lang.String cn.trasen.tsfile.utils.HdfsUtils.hdfsPath
2018-12-17 16:04:47.224 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:04:47.224 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:04:47.264 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:04:47.264 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:04:47.643 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d654825: startup date [Mon Dec 17 16:04:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:04:47.725 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 16:04:47.726 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:04:47.726 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 16:04:47.727 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 16:04:47.728 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 16:04:47.729 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 16:04:47.729 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 16:04:47.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 16:04:47.730 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 16:04:47.733 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 16:04:47.734 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:04:47.807 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:04:47.807 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:04:47.870 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:04:48.807 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d654825: startup date [Mon Dec 17 16:04:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 16:04:48.809 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 16:04:48.847 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 16:04:49.697 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 16:04:49.941 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 16:04:49.942 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 16:04:49.952 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 16:04:49.954 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 16:04:49.955 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 16:04:49.958 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 16:04:49.971 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 16:04:49.989 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=4d654825,type=ConfigurationPropertiesRebinder]
2018-12-17 16:04:50.001 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 16:04:50.232 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 16:04:50.248 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 16:04:50.377 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 16:04:50.378 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 16:04:50.401 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545033890401 with initial instances count: 0
2018-12-17 16:04:50.415 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 16:04:50.432 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 16:04:50.446 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 16:04:50.460 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 16:04:50.491 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 16:04:50.492 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 16:04:50.503 [main] INFO  cn.trasen.Application - Started Application in 11.933 seconds (JVM running for 13.026)
2018-12-17 16:05:17.404 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 16:05:17.404 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 16:05:17.436 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 32 ms
2018-12-17 16:05:17.488 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:05:17.535 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E283C44DDF655B9F326D83B81E8F0C71
2018-12-17 16:05:17.536 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:05:17.536 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:05:17.737 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:05:17.911 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:05:54.613 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:05:54.613 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E283C44DDF655B9F326D83B81E8F0C71
2018-12-17 16:05:54.613 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:05:54.613 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:05:54.716 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:05:54.720 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:06:18.633 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:06:18.634 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E283C44DDF655B9F326D83B81E8F0C71
2018-12-17 16:06:18.634 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:06:18.634 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:06:18.729 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:06:18.732 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:06:32.707 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:06:32.707 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E283C44DDF655B9F326D83B81E8F0C71
2018-12-17 16:06:32.707 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:06:32.708 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:06:32.812 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:06:32.816 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:07:34.085 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:07:34.086 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E283C44DDF655B9F326D83B81E8F0C71
2018-12-17 16:07:34.086 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:07:34.086 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:07:34.180 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:07:34.189 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:09:25.836 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 16:09:25 CST 2018]; root of context hierarchy
2018-12-17 16:09:25.961 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 16:09:25.965 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 16:09:26.162 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:09:26.206 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70cac85b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:27.625 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 16:09:27.651 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@36fcf6c0: startup date [Mon Dec 17 16:09:27 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:09:28.444 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 16:09:28.630 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 16:09:28.840 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 16:09:28.871 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:09:29.073 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$54b0c55e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.285 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.287 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$ad8302b5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.302 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.314 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.320 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.348 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$70cac85b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:09:29.887 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 16:09:29.901 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 16:09:29.902 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 16:09:30.105 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 16:09:30.105 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2454 ms
2018-12-17 16:09:30.565 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 16:09:30.567 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 16:09:30.572 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 16:09:30.572 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 16:09:30.572 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 16:09:30.572 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 16:09:30.573 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 16:09:30.573 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 16:09:30.573 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 16:09:30.606 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 16:09:31.878 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:09:31.879 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:09:31.891 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:09:31.892 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:09:32.234 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@36fcf6c0: startup date [Mon Dec 17 16:09:27 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:09:32.318 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 16:09:32.319 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 16:09:32.320 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 16:09:32.321 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 16:09:32.321 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:09:32.322 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 16:09:32.322 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 16:09:32.323 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 16:09:32.323 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 16:09:32.326 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 16:09:32.326 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:09:32.455 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:09:32.456 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:09:32.532 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:09:33.541 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@36fcf6c0: startup date [Mon Dec 17 16:09:27 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 16:09:33.543 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 16:09:33.587 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 16:09:34.408 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 16:09:34.647 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 16:09:34.649 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 16:09:34.657 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 16:09:34.658 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 16:09:34.660 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 16:09:34.662 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 16:09:34.675 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 16:09:34.691 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=36fcf6c0,type=ConfigurationPropertiesRebinder]
2018-12-17 16:09:34.715 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 16:09:34.856 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 16:09:34.866 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 16:09:34.923 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 16:09:34.923 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 16:09:34.938 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545034174938 with initial instances count: 0
2018-12-17 16:09:34.953 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 16:09:34.973 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 16:09:34.988 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 16:09:35.002 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 16:09:35.037 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 16:09:35.038 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 16:09:35.053 [main] INFO  cn.trasen.Application - Started Application in 10.936 seconds (JVM running for 11.926)
2018-12-17 16:09:46.088 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 16:09:46.089 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 16:09:46.152 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 63 ms
2018-12-17 16:09:46.187 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:09:46.200 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:4047269D19EFBFFA37F8E41FEAE4CF61
2018-12-17 16:09:46.200 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:09:46.201 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:09:46.387 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:09:46.521 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:09:53.314 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 16:09:53.466 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 16:09:53.478 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-17 16:09:53.489 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
2018-12-17 16:09:53.499 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
2018-12-17 16:09:53.544 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2018-12-17 16:09:53.850 [http-nio-6765-exec-1] DEBUG o.a.h.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2018-12-17 16:09:53.878 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 16:09:54.976 [http-nio-6765-exec-1] DEBUG org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
2018-12-17 16:09:55.093 [http-nio-6765-exec-1] DEBUG org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
2018-12-17 16:09:55.119 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
2018-12-17 16:09:55.678 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:55.893 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:55.999 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:56.068 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:56.153 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:56.197 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 16:09:56.592 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 16:10:03.147 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 16:10:03.211 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 16:10:03.350 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 16:10:03.404 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 16:10:03.411 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 16:10:03.415 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 16:10:04.518 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 16:10:04.522 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 16:10:08.195 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 16:10:08.201 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 16:10:08.204 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 16:10:08.208 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 16:10:08.604 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 16:10:10.744 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
2018-12-17 16:10:11.011 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 16:10:13.552 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2018-12-17 16:10:13.660 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2018-12-17 16:10:13.681 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2018-12-17 16:10:13.703 [http-nio-6765-exec-1] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2018-12-17 16:10:13.707 [http-nio-6765-exec-1] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-17 16:10:14.895 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-17 16:10:15.391 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@649c6d6
2018-12-17 16:10:15.551 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@245d0433
2018-12-17 16:10:30.679 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-17 16:10:30.881 [http-nio-6765-exec-1] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 16:10:32.561 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/English.txt: masked=rw-r--r--
2018-12-17 16:10:34.196 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:10:34.239 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:10:34.569 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:10:34.597 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 16:10:34.778 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #0
2018-12-17 16:10:34.779 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 1235ms
2018-12-17 16:10:35.447 [http-nio-6765-exec-1] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/English.txt, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 16:10:35.656 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 started
2018-12-17 16:10:44.571 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:10:44.573 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:11:05.673 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:11:05.674 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:11:05.675 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:11:05.675 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:11:05.762 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #1
2018-12-17 16:11:05.763 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 90ms
2018-12-17 16:11:05.765 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:11:05.765 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:11:15.677 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:11:15.677 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:11:35.780 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:11:35.780 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:11:35.781 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:11:35.781 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:11:35.783 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #2
2018-12-17 16:11:35.783 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:11:35.783 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:11:35.784 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:11:45.782 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:11:45.782 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:12:05.801 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:12:05.801 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:12:05.802 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #3 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:12:05.802 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:12:05.805 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #3
2018-12-17 16:12:05.806 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 5ms
2018-12-17 16:12:05.806 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:12:05.806 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:12:15.804 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:12:15.804 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:12:35.820 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:12:35.820 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:12:35.822 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #4 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:12:35.822 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:12:35.824 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #4
2018-12-17 16:12:35.824 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 4ms
2018-12-17 16:12:35.824 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:12:35.824 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:12:45.823 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:12:45.823 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:13:05.836 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:13:05.836 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:13:05.838 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #5 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:13:05.838 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:13:05.839 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #5
2018-12-17 16:13:05.839 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:13:05.839 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:13:05.839 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:13:15.838 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:13:15.838 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:13:35.856 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:13:35.856 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:13:35.857 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #6 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:13:35.857 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:13:35.859 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #6
2018-12-17 16:13:35.859 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:13:35.859 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:13:35.859 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:13:45.859 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:13:45.859 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:14:05.904 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:14:05.904 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:14:05.905 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #7 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:14:05.905 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:14:05.907 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #7
2018-12-17 16:14:05.907 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:14:05.907 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:14:05.907 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:14:15.906 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:14:15.906 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:14:35.922 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:14:35.922 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:14:35.923 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #8 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:14:35.923 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:14:35.926 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #8
2018-12-17 16:14:35.926 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 4ms
2018-12-17 16:14:35.927 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:14:35.927 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:14:45.924 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:14:45.924 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:15:05.943 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:15:05.943 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:15:05.944 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #9 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:15:05.944 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:15:05.946 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #9
2018-12-17 16:15:05.946 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:15:05.946 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:15:05.946 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:15:15.945 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:15:15.945 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:15:35.960 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:15:35.960 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:15:35.965 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #10 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:15:35.965 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:15:35.966 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #10
2018-12-17 16:15:35.966 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 6ms
2018-12-17 16:15:35.966 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:15:35.966 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:15:45.965 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:15:45.965 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:16:05.982 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:16:05.982 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:16:05.983 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #11 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:16:05.983 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:16:05.985 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #11
2018-12-17 16:16:05.985 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:16:05.985 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:16:05.985 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:16:15.984 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:16:15.984 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:16:35.999 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:16:35.999 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:16:36.000 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #12 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:16:36.000 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:16:36.001 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #12
2018-12-17 16:16:36.002 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:16:36.002 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:16:36.002 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:16:46.001 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:16:46.001 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:17:06.019 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:17:06.020 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:17:06.021 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #13 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:17:06.021 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:17:06.022 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #13
2018-12-17 16:17:06.023 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 4ms
2018-12-17 16:17:06.023 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:17:06.023 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:17:16.022 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:17:16.022 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:17:36.038 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:17:36.039 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:17:36.042 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #14 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:17:36.042 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:17:36.047 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #14
2018-12-17 16:17:36.047 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 9ms
2018-12-17 16:17:36.047 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:17:36.047 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:17:46.044 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:17:46.044 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:18:06.062 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:18:06.063 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:18:06.065 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #15 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:18:06.065 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:18:06.066 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #15
2018-12-17 16:18:06.067 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 5ms
2018-12-17 16:18:06.067 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:18:06.067 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:18:16.067 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:18:16.067 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:18:36.082 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:18:36.082 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:18:36.084 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #16 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:18:36.084 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:18:36.099 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #16
2018-12-17 16:18:36.100 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 18ms
2018-12-17 16:18:36.100 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:18:36.100 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:18:46.085 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:18:46.085 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:19:06.113 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:19:06.115 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:19:06.117 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #17 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:19:06.117 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:19:06.122 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #17
2018-12-17 16:19:06.122 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 9ms
2018-12-17 16:19:06.122 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:19:06.122 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:19:16.118 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:19:16.118 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:19:36.136 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:19:36.136 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:19:36.138 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #18 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:19:36.138 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:19:36.139 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #18
2018-12-17 16:19:36.139 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:19:36.139 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:19:36.140 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:19:46.139 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:19:46.140 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:20:06.157 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:20:06.158 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:20:06.159 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #19 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:20:06.159 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:20:06.169 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #19
2018-12-17 16:20:06.169 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 12ms
2018-12-17 16:20:06.169 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:20:06.169 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:20:16.161 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:20:16.161 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:20:36.182 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:20:36.182 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:20:36.183 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #20 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:20:36.183 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:20:36.185 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #20
2018-12-17 16:20:36.185 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:20:36.185 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:20:36.185 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:20:46.185 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:20:46.185 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:21:06.202 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:21:06.202 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:21:06.214 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #21 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:21:06.214 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:21:06.224 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #21
2018-12-17 16:21:06.224 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 22ms
2018-12-17 16:21:06.224 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:21:06.224 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:21:16.215 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:21:16.215 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:21:36.237 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:21:36.237 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:21:36.238 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #22 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:21:36.238 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:21:36.239 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #22
2018-12-17 16:21:36.239 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 2ms
2018-12-17 16:21:36.240 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:21:36.240 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:21:46.240 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:21:46.240 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:22:06.257 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:22:06.257 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:22:06.258 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #23 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:22:06.258 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:22:06.260 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #23
2018-12-17 16:22:06.260 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:22:06.260 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:22:06.260 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:22:16.259 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:22:16.259 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:22:36.277 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:22:36.277 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:22:36.279 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #24 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:22:36.279 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:22:36.280 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #24
2018-12-17 16:22:36.280 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:22:36.280 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:22:36.280 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:22:46.281 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:22:46.281 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:23:06.296 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:23:06.296 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:23:06.297 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #25 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:23:06.297 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:23:06.312 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #25
2018-12-17 16:23:06.312 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 16ms
2018-12-17 16:23:06.312 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:23:06.313 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:23:16.312 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:23:16.312 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:23:36.327 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:23:36.327 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:23:36.328 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #26 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:23:36.328 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:23:36.330 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #26
2018-12-17 16:23:36.330 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:23:36.330 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:23:36.330 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:23:46.330 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:23:46.330 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:24:06.345 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:24:06.345 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:24:06.347 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #27 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:24:06.347 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:24:06.348 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #27
2018-12-17 16:24:06.348 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:24:06.348 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:24:06.349 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:24:16.348 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:24:16.348 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:24:36.365 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:24:36.365 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:24:36.366 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #28 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:24:36.366 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:24:36.368 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #28
2018-12-17 16:24:36.368 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:24:36.368 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:24:36.368 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:24:46.367 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:24:46.367 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:25:06.379 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:25:06.379 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:25:06.380 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #29 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:25:06.380 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:25:06.382 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #29
2018-12-17 16:25:06.382 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:25:06.382 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:25:06.382 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:25:16.382 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:25:16.382 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:25:36.396 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:25:36.397 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:25:36.401 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #30 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:25:36.401 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:25:36.403 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #30
2018-12-17 16:25:36.403 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 7ms
2018-12-17 16:25:36.404 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:25:36.404 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:25:46.402 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:25:46.402 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:26:06.413 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:26:06.413 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:26:06.415 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #31 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:26:06.415 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:26:06.431 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #31
2018-12-17 16:26:06.431 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 18ms
2018-12-17 16:26:06.431 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:26:06.431 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:26:16.417 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:26:16.417 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:26:36.446 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:26:36.446 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:26:36.447 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #32 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:26:36.447 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:26:36.449 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #32
2018-12-17 16:26:36.449 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:26:36.449 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:26:36.449 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:26:46.448 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:26:46.448 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:27:06.463 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:27:06.463 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:27:06.464 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #33 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:27:06.464 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:27:06.465 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #33
2018-12-17 16:27:06.466 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:27:06.466 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:27:06.466 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:27:16.466 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:27:16.466 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:27:36.480 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:27:36.480 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:27:36.482 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #34 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:27:36.482 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:27:36.483 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #34
2018-12-17 16:27:36.483 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:27:36.484 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:27:36.484 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:27:46.482 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:27:46.482 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:28:06.497 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:28:06.497 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:28:06.499 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #35 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:28:06.499 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:28:06.502 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #35
2018-12-17 16:28:06.502 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 6ms
2018-12-17 16:28:06.503 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:28:06.503 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:28:16.503 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:28:16.503 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:28:36.518 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:28:36.518 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:28:36.519 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #36 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:28:36.519 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:28:36.521 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #36
2018-12-17 16:28:36.521 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:28:36.521 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:28:36.521 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:28:46.520 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:28:46.520 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:29:06.537 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:29:06.537 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:29:06.539 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #37 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:29:06.539 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:29:06.540 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #37
2018-12-17 16:29:06.540 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:29:06.541 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:29:06.541 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:29:16.540 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:29:16.540 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:29:36.555 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:29:36.555 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:29:36.557 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #38 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:29:36.557 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:29:36.558 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #38
2018-12-17 16:29:36.558 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:29:36.558 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:29:36.558 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:29:46.558 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:29:46.558 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:30:06.571 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:30:06.571 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:30:06.573 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #39 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:30:06.573 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:30:06.575 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #39
2018-12-17 16:30:06.575 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 4ms
2018-12-17 16:30:06.575 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:30:06.575 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:30:16.575 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:30:16.575 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:30:36.590 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:30:36.591 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:30:36.592 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #40 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:30:36.592 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:30:36.593 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #40
2018-12-17 16:30:36.593 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:30:36.594 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:30:36.594 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:30:46.593 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:30:46.595 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:31:06.610 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:31:06.611 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:31:06.612 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #41 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:31:06.612 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:31:06.613 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #41
2018-12-17 16:31:06.613 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:31:06.613 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:31:06.613 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:31:08.579 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:31:08.580 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D13DEE8E7E317F3A60C27BE931A47C7A
2018-12-17 16:31:08.581 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:31:08.581 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:31:08.685 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:31:08.691 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:31:16.613 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:31:16.613 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:31:22.282 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:31:22.282 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:D13DEE8E7E317F3A60C27BE931A47C7A
2018-12-17 16:31:22.282 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:31:22.282 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:31:22.375 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:31:22.379 [http-nio-6765-exec-3] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:31:36.628 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:31:36.628 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:31:36.630 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #42 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:31:36.631 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:31:36.633 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #42
2018-12-17 16:31:36.633 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 5ms
2018-12-17 16:31:36.633 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:31:36.633 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:31:46.632 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:31:46.632 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:32:06.649 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:32:06.649 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:32:06.650 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #43 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:32:06.650 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:32:06.652 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #43
2018-12-17 16:32:06.652 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 16:32:06.652 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:32:06.652 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:32:16.651 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 16:32:16.651 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 16:32:36.668 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 16:32:36.668 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 16:32:36.669 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop sending #44 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 16:32:36.669 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 16:32:36.670 [IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (454324291) connection to /192.168.2.199:8020 from hadoop got value #44
2018-12-17 16:32:36.670 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 2ms
2018-12-17 16:32:36.670 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_1148438269_27
2018-12-17 16:32:36.671 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1148438269_27] with renew id 1 executed
2018-12-17 16:33:02.682 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 16:33:02 CST 2018]; root of context hierarchy
2018-12-17 16:33:02.854 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 16:33:02.857 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 16:33:03.001 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:33:03.061 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$8417e8d5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:04.488 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 16:33:04.515 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d0753c9: startup date [Mon Dec 17 16:33:04 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:33:05.330 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 16:33:05.517 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 16:33:05.730 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 16:33:05.762 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:33:05.959 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$67fde5d8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.167 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.170 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$c0d0232f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.184 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.194 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.203 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.221 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$8417e8d5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:33:06.783 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 16:33:06.797 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 16:33:06.799 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 16:33:06.998 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 16:33:06.999 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2484 ms
2018-12-17 16:33:07.468 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 16:33:07.469 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 16:33:07.474 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 16:33:07.475 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 16:33:07.475 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 16:33:07.475 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 16:33:07.476 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 16:33:07.476 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 16:33:07.477 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 16:33:07.510 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 16:33:08.699 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:33:08.701 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:33:08.716 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:33:08.716 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:33:09.060 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d0753c9: startup date [Mon Dec 17 16:33:04 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:33:09.137 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 16:33:09.140 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 16:33:09.140 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 16:33:09.141 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 16:33:09.141 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 16:33:09.142 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:33:09.142 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 16:33:09.143 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 16:33:09.143 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 16:33:09.146 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 16:33:09.146 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:33:09.211 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:33:09.213 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:33:09.282 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:33:10.144 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4d0753c9: startup date [Mon Dec 17 16:33:04 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 16:33:10.145 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 16:33:10.178 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 16:33:10.915 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 16:33:11.170 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 16:33:11.171 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 16:33:11.181 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 16:33:11.183 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 16:33:11.184 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 16:33:11.186 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 16:33:11.200 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 16:33:11.216 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=4d0753c9,type=ConfigurationPropertiesRebinder]
2018-12-17 16:33:11.227 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 16:33:11.374 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 16:33:11.387 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 16:33:11.445 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 16:33:11.445 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 16:33:11.462 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545035591462 with initial instances count: 0
2018-12-17 16:33:11.475 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 16:33:11.494 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 16:33:11.510 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 16:33:11.524 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 16:33:11.567 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 16:33:11.590 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 16:33:11.595 [main] INFO  cn.trasen.Application - Started Application in 10.616 seconds (JVM running for 11.509)
2018-12-17 16:39:02.657 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 16:39:02.658 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 16:39:02.704 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 46 ms
2018-12-17 16:39:02.765 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:39:02.790 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:8E70F1597F9CCBD4A550ED8CA8628393
2018-12-17 16:39:02.790 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:39:02.791 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:39:03.015 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:39:03.284 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:41:50.152 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 16:41:50 CST 2018]; root of context hierarchy
2018-12-17 16:41:50.289 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 16:41:50.295 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 16:41:50.492 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:41:50.538 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b46f3949] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:51.992 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 16:41:52.020 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9d7ccfe: startup date [Mon Dec 17 16:41:52 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:41:52.850 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 16:41:53.059 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 16:41:53.335 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 16:41:53.366 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 16:41:53.593 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$9855364c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.795 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.799 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$f12773a3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.816 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.829 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.836 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:53.854 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b46f3949] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 16:41:54.399 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 16:41:54.411 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 16:41:54.412 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 16:41:54.621 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 16:41:54.622 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2602 ms
2018-12-17 16:41:55.372 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 16:41:55.374 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 16:41:55.379 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 16:41:55.380 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 16:41:55.380 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 16:41:55.380 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 16:41:55.381 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 16:41:55.381 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 16:41:55.381 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 16:41:55.420 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 16:41:56.885 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:41:56.885 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:41:56.901 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 16:41:56.901 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 16:41:57.266 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9d7ccfe: startup date [Mon Dec 17 16:41:52 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 16:41:57.343 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 16:41:57.344 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 16:41:57.344 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 16:41:57.344 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 16:41:57.344 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 16:41:57.345 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 16:41:57.346 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:41:57.347 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 16:41:57.347 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 16:41:57.349 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 16:41:57.350 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 16:41:57.418 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:41:57.418 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:41:57.488 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 16:41:58.347 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@9d7ccfe: startup date [Mon Dec 17 16:41:52 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 16:41:58.349 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 16:41:58.380 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 16:41:59.175 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 16:41:59.413 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 16:41:59.415 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 16:41:59.423 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 16:41:59.425 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 16:41:59.426 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 16:41:59.430 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 16:41:59.442 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 16:41:59.457 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=9d7ccfe,type=ConfigurationPropertiesRebinder]
2018-12-17 16:41:59.470 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 16:41:59.634 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 16:41:59.643 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 16:41:59.700 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 16:41:59.700 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 16:41:59.711 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545036119711 with initial instances count: 0
2018-12-17 16:41:59.724 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 16:41:59.738 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 16:41:59.754 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 16:41:59.768 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 16:41:59.828 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 16:41:59.828 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 16:41:59.836 [main] INFO  cn.trasen.Application - Started Application in 11.428 seconds (JVM running for 12.488)
2018-12-17 16:42:57.919 [http-nio-6765-exec-10] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 16:42:57.919 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 16:42:57.961 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 42 ms
2018-12-17 16:42:58.063 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:42:58.104 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:1EE1016B08434A5C860A10BE755B748B
2018-12-17 16:42:58.105 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:42:58.106 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:42:58.338 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:42:58.579 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:58:39.303 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:58:39.305 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:1EE1016B08434A5C860A10BE755B748B
2018-12-17 16:58:39.305 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:58:39.305 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:58:39.399 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:58:39.404 [http-nio-6765-exec-8] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 16:59:42.365 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 16:59:42.366 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:1EE1016B08434A5C860A10BE755B748B
2018-12-17 16:59:42.366 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 16:59:42.366 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 16:59:42.468 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 16:59:42.471 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:00:00.508 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 17:00:00.677 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 17:00:00.687 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-17 17:00:00.699 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
2018-12-17 17:00:00.708 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
2018-12-17 17:00:00.755 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2018-12-17 17:00:01.049 [http-nio-6765-exec-9] DEBUG o.a.h.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2018-12-17 17:00:01.077 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 17:00:02.036 [http-nio-6765-exec-9] DEBUG org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
2018-12-17 17:00:02.164 [http-nio-6765-exec-9] DEBUG org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
2018-12-17 17:00:02.191 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
2018-12-17 17:00:02.793 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.029 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.146 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.222 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.313 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.363 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:00:03.765 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:00:10.812 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:00:10.868 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:00:11.005 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:00:11.064 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:00:11.070 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 17:00:11.074 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 17:00:12.200 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 17:00:12.204 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 17:00:16.111 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 17:00:16.115 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 17:00:16.119 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 17:00:16.123 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 17:00:16.550 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 17:00:18.831 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
2018-12-17 17:00:19.117 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 17:00:21.797 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2018-12-17 17:00:21.913 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2018-12-17 17:00:21.934 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2018-12-17 17:00:21.960 [http-nio-6765-exec-9] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2018-12-17 17:00:21.964 [http-nio-6765-exec-9] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-17 17:00:23.265 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-17 17:00:23.806 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@40d8db14
2018-12-17 17:00:23.968 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@2ffcb4cd
2018-12-17 17:00:40.171 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-17 17:00:40.389 [http-nio-6765-exec-9] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 17:00:41.714 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls: masked=rw-r--r--
2018-12-17 17:00:43.463 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:00:43.510 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:00:43.870 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:00:43.901 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 17:00:43.954 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #0
2018-12-17 17:00:43.955 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 1188ms
2018-12-17 17:00:44.637 [http-nio-6765-exec-9] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 17:00:44.864 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 started
2018-12-17 17:00:53.872 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:00:53.872 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:01:14.878 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:01:14.879 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:01:14.881 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:01:14.881 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:01:14.882 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #1
2018-12-17 17:01:14.883 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 5ms
2018-12-17 17:01:14.884 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:01:14.884 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:01:24.882 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:01:24.883 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:01:44.904 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:01:44.905 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:01:44.906 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:01:44.906 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:01:44.937 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #2
2018-12-17 17:01:44.937 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 33ms
2018-12-17 17:01:44.938 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:01:44.938 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:01:54.908 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:01:54.908 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:02:14.966 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:02:14.966 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:02:14.967 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #3 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:02:14.967 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:02:14.969 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #3
2018-12-17 17:02:14.969 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:02:14.969 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:02:14.970 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:02:24.969 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:02:24.969 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:02:44.984 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:02:44.984 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:02:44.986 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #4 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:02:44.986 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:02:44.987 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #4
2018-12-17 17:02:44.987 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:02:44.988 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:02:44.988 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:02:54.987 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:02:54.987 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:03:15.005 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:03:15.005 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:03:15.007 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #5 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:03:15.007 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:03:15.008 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #5
2018-12-17 17:03:15.008 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:03:15.008 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:03:15.008 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:03:25.007 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:03:25.007 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:03:45.022 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:03:45.022 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:03:45.023 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:03:45.023 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #6 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:03:45.025 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #6
2018-12-17 17:03:45.025 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:03:45.025 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:03:45.025 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:03:55.024 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:03:55.024 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:04:15.041 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:04:15.042 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:04:15.051 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #7 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:04:15.051 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:04:15.053 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #7
2018-12-17 17:04:15.053 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 13ms
2018-12-17 17:04:15.053 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:04:15.054 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:04:25.054 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:04:25.055 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:04:45.071 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:04:45.072 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:04:45.073 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #8 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:04:45.073 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:04:45.075 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #8
2018-12-17 17:04:45.075 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 4ms
2018-12-17 17:04:45.075 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:04:45.075 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:04:55.074 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:04:55.074 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:05:15.089 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:05:15.089 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:05:15.091 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #9 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:05:15.091 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:05:15.092 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #9
2018-12-17 17:05:15.092 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:05:15.092 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:05:15.092 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:05:25.092 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:05:25.092 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:05:45.106 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:05:45.106 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:05:45.107 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #10 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:05:45.107 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:05:45.109 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #10
2018-12-17 17:05:45.109 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:05:45.109 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:05:45.109 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:05:55.108 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:05:55.108 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:06:15.125 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:06:15.125 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:06:15.126 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #11 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:06:15.127 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:06:15.128 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #11
2018-12-17 17:06:15.128 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 3ms
2018-12-17 17:06:15.128 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:06:15.128 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:06:25.127 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:06:25.127 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:06:45.145 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:06:45.145 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:06:45.146 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop sending #12 org.apache.hadoop.hdfs.protocol.ClientProtocol.renewLease
2018-12-17 17:06:45.146 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:06:45.148 [IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (2011130191) connection to /192.168.2.199:8020 from hadoop got value #12
2018-12-17 17:06:45.150 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: renewLease took 5ms
2018-12-17 17:06:45.150 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewed for client DFSClient_NONMAPREDUCE_-2034966429_35
2018-12-17 17:06:45.150 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_-2034966429_35] with renew id 1 executed
2018-12-17 17:07:38.843 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 17:07:38 CST 2018]; root of context hierarchy
2018-12-17 17:07:39.050 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:07:39.052 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:07:39.233 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:07:39.277 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$bd7a4975] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:40.787 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:07:40.826 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2c6aed22: startup date [Mon Dec 17 17:07:40 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:07:41.938 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:07:42.121 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:07:42.345 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 17:07:42.374 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:07:42.827 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$a1604678] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.072 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.075 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$fa3283cf] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.096 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.111 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.120 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.164 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$bd7a4975] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:07:43.815 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:07:43.832 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:07:43.833 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:07:44.193 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:07:44.194 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 3368 ms
2018-12-17 17:07:45.154 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:07:45.156 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:07:45.161 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:07:45.162 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:07:45.162 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:07:45.162 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:07:45.162 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:07:45.162 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:07:45.163 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:07:45.202 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:07:47.200 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:07:47.200 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:07:47.214 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:07:47.214 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:07:47.618 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2c6aed22: startup date [Mon Dec 17 17:07:40 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:07:47.703 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:07:47.704 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:07:47.704 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:07:47.705 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:07:47.705 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:07:47.705 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:07:47.706 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:07:47.707 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:07:47.707 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.commons.CommonsMultipartFile)
2018-12-17 17:07:47.709 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:07:47.710 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:07:47.789 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:07:47.789 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:07:47.864 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:07:48.872 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2c6aed22: startup date [Mon Dec 17 17:07:40 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 17:07:48.875 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:07:48.927 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:07:49.842 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:07:50.096 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:07:50.097 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:07:50.112 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:07:50.113 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:07:50.116 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:07:50.119 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:07:50.135 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:07:50.162 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=2c6aed22,type=ConfigurationPropertiesRebinder]
2018-12-17 17:07:50.177 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:07:50.378 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:07:50.392 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:07:50.452 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:07:50.452 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:07:50.464 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545037670464 with initial instances count: 0
2018-12-17 17:07:50.481 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:07:50.495 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:07:50.515 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:07:50.529 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:07:50.557 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:07:50.558 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:07:50.561 [main] INFO  cn.trasen.Application - Started Application in 13.49 seconds (JVM running for 14.414)
2018-12-17 17:08:21.035 [http-nio-6765-exec-10] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:08:21.035 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:08:21.092 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 57 ms
2018-12-17 17:08:21.140 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:08:21.157 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E14A21573FA0C36268C55115632C0313
2018-12-17 17:08:21.158 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:08:21.159 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:08:21.356 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:08:21.538 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:08:21.759 [http-nio-6765-exec-10] WARN  o.s.w.s.m.support.DefaultHandlerExceptionResolver - Failed to convert request element: org.springframework.web.method.annotation.MethodArgumentConversionNotSupportedException: Failed to convert value of type 'org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile' to required type 'org.springframework.web.multipart.commons.CommonsMultipartFile'; nested exception is java.lang.IllegalStateException: Cannot convert value of type 'org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile' to required type 'org.springframework.web.multipart.commons.CommonsMultipartFile': no matching editors or conversion strategy found
2018-12-17 17:08:37.631 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:08:37.631 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:E14A21573FA0C36268C55115632C0313
2018-12-17 17:08:37.631 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:08:37.633 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:08:37.727 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:08:37.732 [http-nio-6765-exec-9] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:08:37.736 [http-nio-6765-exec-9] WARN  o.s.w.s.m.support.DefaultHandlerExceptionResolver - Failed to convert request element: org.springframework.web.method.annotation.MethodArgumentConversionNotSupportedException: Failed to convert value of type 'org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile' to required type 'org.springframework.web.multipart.commons.CommonsMultipartFile'; nested exception is java.lang.IllegalStateException: Cannot convert value of type 'org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile' to required type 'org.springframework.web.multipart.commons.CommonsMultipartFile': no matching editors or conversion strategy found
2018-12-17 17:13:06.720 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 17:13:06 CST 2018]; root of context hierarchy
2018-12-17 17:13:06.887 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:13:06.890 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:13:07.187 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:13:07.232 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$219d8b3d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:08.847 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:13:08.870 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4c48fe92: startup date [Mon Dec 17 17:13:08 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:13:09.705 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:13:09.966 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:13:10.191 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 17:13:10.218 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:13:10.416 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$5838840] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.624 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.627 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$5e55c597] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.642 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.653 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.659 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:10.678 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$219d8b3d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:13:11.207 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:13:11.218 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:13:11.219 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:13:11.419 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:13:11.419 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2549 ms
2018-12-17 17:13:11.863 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:13:11.864 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:13:11.870 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:13:11.870 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:13:11.871 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:13:11.871 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:13:11.871 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:13:11.871 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:13:11.871 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:13:11.905 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:13:13.286 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:13:13.286 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:13:13.299 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:13:13.299 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:13:13.652 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4c48fe92: startup date [Mon Dec 17 17:13:08 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:13:13.734 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:13:13.735 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:13:13.736 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:13:13.736 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:13:13.737 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:13:13.738 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:13:13.738 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:13:13.739 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 17:13:13.739 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:13:13.741 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:13:13.742 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:13:13.817 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:13:13.817 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:13:13.888 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:13:14.791 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@4c48fe92: startup date [Mon Dec 17 17:13:08 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 17:13:14.793 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:13:14.832 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:13:15.576 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:13:15.841 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:13:15.843 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:13:15.853 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:13:15.855 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:13:15.856 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:13:15.859 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:13:15.872 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:13:15.897 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=4c48fe92,type=ConfigurationPropertiesRebinder]
2018-12-17 17:13:15.912 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:13:16.086 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:13:16.096 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:13:16.156 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:13:16.157 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:13:16.171 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545037996171 with initial instances count: 0
2018-12-17 17:13:16.186 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:13:16.205 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:13:16.221 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:13:16.234 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:13:16.267 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:13:16.268 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:13:16.278 [main] INFO  cn.trasen.Application - Started Application in 11.29 seconds (JVM running for 12.11)
2018-12-17 17:13:45.968 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:13:45.969 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:13:46.009 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 40 ms
2018-12-17 17:13:46.090 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:13:46.124 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:9D10A59A499EF561DFC949333B55774F
2018-12-17 17:13:46.124 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:13:46.125 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:13:46.368 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:13:46.627 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:15:39.328 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:15:39.329 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:9D10A59A499EF561DFC949333B55774F
2018-12-17 17:15:39.329 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:15:39.330 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:15:39.413 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:15:39.419 [http-nio-6765-exec-2] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:21:39.961 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614: startup date [Mon Dec 17 17:21:39 CST 2018]; root of context hierarchy
2018-12-17 17:21:40.124 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:21:40.127 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:21:40.295 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:21:40.341 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b9df98c2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:41.801 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:21:41.839 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3bd3d05e: startup date [Mon Dec 17 17:21:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:21:42.637 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:21:42.894 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:21:43.104 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 17:21:43.135 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:21:43.386 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$9dc595c5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.609 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.611 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$f697d31c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.625 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.638 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.644 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:43.662 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b9df98c2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:21:44.299 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:21:44.310 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:21:44.311 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:21:44.505 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:21:44.507 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2668 ms
2018-12-17 17:21:44.977 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:21:44.979 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:21:44.983 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:21:44.984 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:21:44.984 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:21:44.984 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:21:44.985 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:21:44.985 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:21:44.985 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:21:45.015 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:21:46.209 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:21:46.211 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:21:46.224 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:21:46.224 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:21:46.579 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3bd3d05e: startup date [Mon Dec 17 17:21:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614
2018-12-17 17:21:46.660 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:21:46.661 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:21:46.662 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:21:46.662 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:21:46.664 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:21:46.664 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:21:46.664 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:21:46.665 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:21:46.665 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 17:21:46.668 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:21:46.668 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:21:46.739 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:21:46.739 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:21:46.807 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:21:47.686 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@3bd3d05e: startup date [Mon Dec 17 17:21:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@5a411614] and template loader path [classpath:/templates/]
2018-12-17 17:21:47.687 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:21:47.725 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:21:48.539 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:21:48.785 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:21:48.786 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:21:48.802 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:21:48.804 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:21:48.805 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:21:48.808 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:21:48.821 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:21:48.841 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=3bd3d05e,type=ConfigurationPropertiesRebinder]
2018-12-17 17:21:48.850 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:21:49.002 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:21:49.012 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:21:49.070 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:21:49.070 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:21:49.084 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545038509084 with initial instances count: 0
2018-12-17 17:21:49.096 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:21:49.113 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:21:49.127 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:21:49.140 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:21:49.168 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:21:49.169 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:21:49.174 [main] INFO  cn.trasen.Application - Started Application in 10.891 seconds (JVM running for 11.773)
2018-12-17 17:22:36.080 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:22:36.081 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:22:36.123 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 42 ms
2018-12-17 17:22:36.181 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:22:36.205 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:98EDA31995E4042C978C603D74563438
2018-12-17 17:22:36.205 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:22:36.206 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:22:36.435 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:22:36.648 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:24:39.908 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f: startup date [Mon Dec 17 17:24:39 CST 2018]; root of context hierarchy
2018-12-17 17:24:40.107 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:24:40.109 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:24:40.442 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:24:40.492 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$ca70d2f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:41.982 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:24:42.007 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@20011bf: startup date [Mon Dec 17 17:24:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:24:42.940 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:24:43.145 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:24:43.373 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 17:24:43.425 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:24:43.613 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$ae56cff3] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.856 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.858 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$7290d4a] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.873 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.885 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.891 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:43.910 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$ca70d2f0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:24:44.495 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:24:44.508 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:24:44.510 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:24:44.727 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:24:44.728 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2720 ms
2018-12-17 17:24:45.209 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:24:45.212 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:24:45.217 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:24:45.218 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:24:45.218 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:24:45.218 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:24:45.218 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:24:45.219 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:24:45.219 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:24:45.250 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:24:46.622 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:24:46.622 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:24:46.635 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:24:46.635 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:24:47.026 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@20011bf: startup date [Mon Dec 17 17:24:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:24:47.141 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:24:47.142 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:24:47.143 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:24:47.143 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:24:47.144 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:24:47.144 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:24:47.144 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:24:47.145 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:24:47.145 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(org.springframework.web.multipart.MultipartFile)
2018-12-17 17:24:47.150 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:24:47.151 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:24:47.323 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:24:47.323 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:24:47.389 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:24:48.246 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@20011bf: startup date [Mon Dec 17 17:24:42 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f] and template loader path [classpath:/templates/]
2018-12-17 17:24:48.248 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:24:48.283 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:24:49.072 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:24:49.327 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:24:49.329 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:24:49.337 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:24:49.339 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:24:49.340 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:24:49.342 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:24:49.355 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:24:49.372 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=20011bf,type=ConfigurationPropertiesRebinder]
2018-12-17 17:24:49.380 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:24:49.670 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:24:49.680 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:24:49.745 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:24:49.745 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:24:49.793 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545038689793 with initial instances count: 0
2018-12-17 17:24:49.808 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:24:49.823 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:24:49.839 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:24:49.855 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:24:49.887 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:24:49.888 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:24:49.892 [main] INFO  cn.trasen.Application - Started Application in 11.979 seconds (JVM running for 12.93)
2018-12-17 17:25:31.731 [http-nio-6765-exec-10] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:25:31.732 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:25:31.782 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 50 ms
2018-12-17 17:25:31.880 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:25:31.904 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:DE1D9E458DC7D1750247A9200C0A2D1E
2018-12-17 17:25:31.904 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:25:31.904 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:25:32.135 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:25:32.365 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:26:39.647 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f: startup date [Mon Dec 17 17:26:39 CST 2018]; root of context hierarchy
2018-12-17 17:26:39.779 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:26:39.782 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:26:39.962 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:26:40.005 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b55a0dcc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:41.413 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:26:41.441 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a03d65c: startup date [Mon Dec 17 17:26:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:26:42.198 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:26:42.381 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:26:42.588 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=520aad85-302c-363c-89b2-ee68fac45ad9
2018-12-17 17:26:42.618 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:26:42.809 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$99400acf] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.033 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.036 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$f2124826] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.057 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.070 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.078 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.098 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b55a0dcc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:26:43.712 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:26:43.726 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:26:43.728 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:26:43.943 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:26:43.943 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2503 ms
2018-12-17 17:26:44.436 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:26:44.438 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:26:44.443 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:26:44.443 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:26:44.443 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:26:44.443 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:26:44.444 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:26:44.445 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:26:44.445 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:26:44.476 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:26:46.144 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:26:46.144 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:26:46.157 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:26:46.158 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:26:46.542 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a03d65c: startup date [Mon Dec 17 17:26:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:26:46.636 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:26:46.637 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:26:46.637 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:26:46.638 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:26:46.638 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:26:46.638 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:26:46.639 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:26:46.640 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:26:46.641 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:26:46.643 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:26:46.644 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:26:46.722 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:26:46.722 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:26:46.799 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:26:47.907 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2a03d65c: startup date [Mon Dec 17 17:26:41 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f] and template loader path [classpath:/templates/]
2018-12-17 17:26:47.909 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:26:47.950 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:26:48.690 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:26:48.930 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:26:48.932 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:26:48.940 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:26:48.941 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:26:48.942 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:26:48.945 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:26:48.958 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:26:48.979 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=2a03d65c,type=ConfigurationPropertiesRebinder]
2018-12-17 17:26:48.989 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:26:49.185 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:26:49.194 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:26:49.248 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:26:49.248 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:26:49.261 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545038809260 with initial instances count: 0
2018-12-17 17:26:49.275 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:26:49.290 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:26:49.305 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:26:49.318 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:26:49.354 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:26:49.355 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:26:49.359 [main] INFO  cn.trasen.Application - Started Application in 11.371 seconds (JVM running for 12.2)
2018-12-17 17:27:38.517 [http-nio-6765-exec-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:27:38.518 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:27:38.554 [http-nio-6765-exec-1] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 36 ms
2018-12-17 17:27:38.892 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:27:39.028 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:BB1FEA351799DDAE1B718EA58B434812
2018-12-17 17:27:39.028 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:27:39.029 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:7569cb73-fe0b-4ded-bf97-e685a5f72d8d
2018-12-17 17:27:39.742 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"运营部","deptname":"创星集团","password":"1000:28bdcb516348cff303c44bf2d3290262:0c5e4609acf72c4cff28c25be79d2881","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 15:37:00","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","usericon":null,"token":"7569cb73-fe0b-4ded-bf97-e685a5f72d8d","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('TS-HNCX')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"TS-HNCX","hospName":"湖南创星科技股份有限公司","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:27:40.081 [http-nio-6765-exec-1] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:29:32.811 [main] INFO  o.s.c.a.AnnotationConfigApplicationContext - Refreshing org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f: startup date [Mon Dec 17 17:29:32 CST 2018]; root of context hierarchy
2018-12-17 17:29:32.970 [background-preinit] DEBUG org.jboss.logging - Logging Provider: org.jboss.logging.Slf4jLoggerProvider found via system property
2018-12-17 17:29:32.972 [background-preinit] INFO  org.hibernate.validator.internal.util.Version - HV000001: Hibernate Validator 5.3.6.Final
2018-12-17 17:29:33.182 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:29:33.237 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'configurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f95747de] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:34.658 [main] INFO  cn.trasen.Application - No active profile set, falling back to default profiles: default
2018-12-17 17:29:34.684 [main] INFO  o.s.b.c.e.AnnotationConfigEmbeddedWebApplicationContext - Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7123be6c: startup date [Mon Dec 17 17:29:34 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:29:35.451 [main] INFO  o.s.d.r.config.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode!
2018-12-17 17:29:35.636 [main] WARN  tk.mybatis.spring.mapper.ClassPathMapperScanner - No MyBatis mapper was found in '[cn.trasen]' package. Please check your configuration.
2018-12-17 17:29:35.840 [main] INFO  o.springframework.cloud.context.scope.GenericScope - BeanFactory id=37f73cb0-e338-30f1-ba86-dadd44da3bfe
2018-12-17 17:29:35.867 [main] INFO  o.s.b.f.a.AutowiredAnnotationBeanPostProcessor - JSR-330 'javax.inject.Inject' annotation found and supported for autowiring
2018-12-17 17:29:36.065 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration' of type [org.springframework.transaction.annotation.ProxyTransactionManagementConfiguration$$EnhancerBySpringCGLIB$$dd3d44e1] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.270 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.datasource.druid-cn.trasen.BootComm.DruidStatProperties' of type [cn.trasen.BootComm.DruidStatProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.273 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidConfiguration' of type [cn.trasen.BootComm.DruidConfiguration$$EnhancerBySpringCGLIB$$360f8238] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.286 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatPointcut' of type [org.springframework.aop.support.JdkRegexpMethodPointcut] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.297 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatInterceptor' of type [com.alibaba.druid.support.spring.stat.DruidStatInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.303 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'druidStatAdvisor' of type [org.springframework.aop.support.DefaultPointcutAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.322 [main] INFO  o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$f95747de] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2018-12-17 17:29:36.863 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat initialized with port(s): 6765 (http)
2018-12-17 17:29:36.877 [main] INFO  org.apache.catalina.core.StandardService - Starting service [Tomcat]
2018-12-17 17:29:36.879 [main] INFO  org.apache.catalina.core.StandardEngine - Starting Servlet Engine: Apache Tomcat/8.5.27
2018-12-17 17:29:37.077 [localhost-startStop-1] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring embedded WebApplicationContext
2018-12-17 17:29:37.078 [localhost-startStop-1] INFO  org.springframework.web.context.ContextLoader - Root WebApplicationContext: initialization completed in 2394 ms
2018-12-17 17:29:37.521 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'statViewServlet' to [/druid/*]
2018-12-17 17:29:37.524 [localhost-startStop-1] INFO  o.s.boot.web.servlet.ServletRegistrationBean - Mapping servlet: 'dispatcherServlet' to [/]
2018-12-17 17:29:37.529 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'characterEncodingFilter' to: [/*]
2018-12-17 17:29:37.530 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'hiddenHttpMethodFilter' to: [/*]
2018-12-17 17:29:37.531 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'httpPutFormContentFilter' to: [/*]
2018-12-17 17:29:37.531 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'requestContextFilter' to: [/*]
2018-12-17 17:29:37.531 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'webStatFilter' to urls: [/*]
2018-12-17 17:29:37.532 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'loginFilter' to: [/*]
2018-12-17 17:29:37.532 [localhost-startStop-1] INFO  o.s.boot.web.servlet.FilterRegistrationBean - Mapping filter: 'SSOFilters' to: [/*]
2018-12-17 17:29:37.564 [localhost-startStop-1] INFO  cn.trasen.BootComm.filter.SSOFilter - ============SSOFilter 启动==================== SSO Domain Serverhttp://39.104.149.133:8080
2018-12-17 17:29:38.854 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:29:38.854 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:29:38.866 [main] WARN  com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.
2018-12-17 17:29:38.866 [main] INFO  com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2018-12-17 17:29:39.210 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerAdapter - Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7123be6c: startup date [Mon Dec 17 17:29:34 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f
2018-12-17 17:29:39.290 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/update/{businessId}/{tempBusinessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.updateTempBusinessId(java.lang.String,java.lang.String)
2018-12-17 17:29:39.291 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list/{businessId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.getFileListByBusiId(java.lang.String)
2018-12-17 17:29:39.291 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/v2/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.upload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile)
2018-12-17 17:29:39.292 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/upload],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.uploadFile(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:29:39.292 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/delete/{fileId}],methods=[POST]}" onto public cn.trasen.core.entity.Result cn.trasen.tsfile.controller.FileController.deleteFileById(java.lang.String)
2018-12-17 17:29:39.293 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/list],methods=[POST]}" onto public cn.trasen.BootComm.model.DataSet<cn.trasen.tsfile.model.BaseFile> cn.trasen.tsfile.controller.FileController.getFileList(cn.trasen.core.feature.orm.mybatis.Page,cn.trasen.tsfile.model.BaseFile)
2018-12-17 17:29:39.293 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/file/download/{fileId}],methods=[GET]}" onto public void cn.trasen.tsfile.controller.FileController.downloadFile(java.lang.String,javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:29:39.294 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hdfs/upload],methods=[POST]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.HDFSupload(javax.servlet.http.HttpServletRequest,org.springframework.web.multipart.MultipartFile,java.lang.String)
2018-12-17 17:29:39.295 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/hello]}" onto public java.lang.String cn.trasen.tsfile.controller.HdfsController.hello()
2018-12-17 17:29:39.297 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error]}" onto public org.springframework.http.ResponseEntity<java.util.Map<java.lang.String, java.lang.Object>> org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest)
2018-12-17 17:29:39.298 [main] INFO  o.s.w.s.m.m.a.RequestMappingHandlerMapping - Mapped "{[/error],produces=[text/html]}" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse)
2018-12-17 17:29:39.362 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:29:39.362 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:29:39.436 [main] INFO  o.s.web.servlet.handler.SimpleUrlHandlerMapping - Mapped URL path [/**/favicon.ico] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler]
2018-12-17 17:29:40.302 [main] INFO  o.s.ui.freemarker.SpringTemplateLoader - SpringTemplateLoader for FreeMarker: using resource loader [org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@7123be6c: startup date [Mon Dec 17 17:29:34 CST 2018]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@1506f20f] and template loader path [classpath:/templates/]
2018-12-17 17:29:40.304 [main] INFO  o.s.w.servlet.view.freemarker.FreeMarkerConfigurer - ClassTemplateLoader for Spring macros added to FreeMarker configuration
2018-12-17 17:29:40.341 [main] WARN  o.s.b.a.freemarker.FreeMarkerAutoConfiguration - Cannot find template location(s): [classpath:/templates/] (please add some templates, check your FreeMarker configuration, or set spring.freemarker.checkTemplateLocation=false)
2018-12-17 17:29:41.067 [main] WARN  o.s.c.s.e.EurekaStarterDeprecationWarningAutoConfiguration - spring-cloud-starter-eureka is deprecated as of Spring Cloud Netflix 1.4.0, please migrate to spring-cloud-starter-netflix-eureka
2018-12-17 17:29:41.301 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Registering beans for JMX exposure on startup
2018-12-17 17:29:41.302 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'dataSource' has been autodetected for JMX exposure
2018-12-17 17:29:41.312 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'environmentManager' has been autodetected for JMX exposure
2018-12-17 17:29:41.314 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'configurationPropertiesRebinder' has been autodetected for JMX exposure
2018-12-17 17:29:41.316 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Bean with name 'refreshScope' has been autodetected for JMX exposure
2018-12-17 17:29:41.318 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'environmentManager': registering with JMX server as MBean [org.springframework.cloud.context.environment:name=environmentManager,type=EnvironmentManager]
2018-12-17 17:29:41.331 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'refreshScope': registering with JMX server as MBean [org.springframework.cloud.context.scope.refresh:name=refreshScope,type=RefreshScope]
2018-12-17 17:29:41.348 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located managed bean 'configurationPropertiesRebinder': registering with JMX server as MBean [org.springframework.cloud.context.properties:name=configurationPropertiesRebinder,context=7123be6c,type=ConfigurationPropertiesRebinder]
2018-12-17 17:29:41.359 [main] INFO  o.s.jmx.export.annotation.AnnotationMBeanExporter - Located MBean 'dataSource': registering with JMX server as MBean [com.alibaba.druid.pool:name=dataSource,type=DruidDataSource]
2018-12-17 17:29:41.514 [main] INFO  o.s.context.support.DefaultLifecycleProcessor - Starting beans in phase 0
2018-12-17 17:29:41.525 [main] INFO  o.s.cloud.netflix.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
2018-12-17 17:29:41.581 [main] INFO  com.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
2018-12-17 17:29:41.581 [main] INFO  com.netflix.discovery.DiscoveryClient - Client configured to neither register nor query for data.
2018-12-17 17:29:41.596 [main] INFO  com.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1545038981595 with initial instances count: 0
2018-12-17 17:29:41.609 [main] INFO  o.s.c.n.e.serviceregistry.EurekaServiceRegistry - Registering application ts-file with eureka with status UP
2018-12-17 17:29:41.629 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-6765"]
2018-12-17 17:29:41.644 [main] INFO  org.apache.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-6765"]
2018-12-17 17:29:41.657 [main] INFO  org.apache.tomcat.util.net.NioSelectorPool - Using a shared selector for servlet write/read
2018-12-17 17:29:41.710 [main] INFO  o.s.b.c.e.tomcat.TomcatEmbeddedServletContainer - Tomcat started on port(s): 6765 (http)
2018-12-17 17:29:41.714 [main] INFO  o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 6765
2018-12-17 17:29:41.718 [main] INFO  cn.trasen.Application - Started Application in 10.767 seconds (JVM running for 11.664)
2018-12-17 17:30:23.269 [http-nio-6765-exec-10] INFO  o.a.c.c.C.[Tomcat].[localhost].[/ts-file] - Initializing Spring FrameworkServlet 'dispatcherServlet'
2018-12-17 17:30:23.269 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization started
2018-12-17 17:30:23.335 [http-nio-6765-exec-10] INFO  org.springframework.web.servlet.DispatcherServlet - FrameworkServlet 'dispatcherServlet': initialization completed in 66 ms
2018-12-17 17:30:23.393 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 校验 login Filter.....
2018-12-17 17:30:23.422 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - doFilter request Id:C36CB1C54F177DFAC9B78828DA35AA70
2018-12-17 17:30:23.422 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - 服务请求地址：http://localhost/ts-file/hdfs/upload/ token:null
2018-12-17 17:30:23.423 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - Cookie中的 sessionId:a0a2679e-5024-4153-9f59-d1eab1a336f4
2018-12-17 17:30:23.656 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - body:{"msg":"认证成功","uid":{"id":"admin","corpcode":"TS-JT","usercode":"admin","oldusercode":"admin","username":"系统管理员","deptcode":"TS-JT","pdcode":"","pdName":"","deptname":"创星集团","password":"1000:2193e8a478d6e830526ea5b3504b9a01:301d9f3cf186a0533ad4bb98a0d325c4","oldpassword":"0192023a7bbd73250516f069df18b500","status":1,"logintime":"2018-12-17 17:29:53","logouttime":null,"activetime":-2209017600000,"remarkid":"","loginip":"222.247.55.194","emailaccount":"","emailpassword":"","emailaddress":"","emailpop3":"","emailsmtp":"","emailsubject":"","agentcode":"","agentstartdatetime":"1900-01-01 00:00:00","agentenddatetime":"1900-01-01 00:00:00","wxcode":null,"hrcode":"1","mobileNo":"18977777777","autoexittime":1440,"logins":null,"appuser":"","apptime":"1900-01-01 00:00:00","updateuser":"","updatetime":"1900-01-01 00:00:00","dleader":"T002;","dutyCode":"系统管理员","sessionid":"a0a2679e-5024-4153-9f59-d1eab1a336f4","usericon":null,"token":"a0a2679e-5024-4153-9f59-d1eab1a336f4","wxuserid":null,"wxdepartment":null,"sex":"0","orgRang":"('TS-JT')","corpList":"('')","sysRoleCode":"ADMIN,SYS_ROLE_EM","hospCode":"","hospName":"","corpName":"创星集团","deptList":""},"code":"0"}
2018-12-17 17:30:23.851 [http-nio-6765-exec-10] INFO  cn.trasen.BootComm.filter.SSOFilter - userInfo 相关信息：系统管理员 usercode:admin
2018-12-17 17:30:49.130 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 17:30:49.307 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2018-12-17 17:30:49.320 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
2018-12-17 17:30:49.332 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
2018-12-17 17:30:49.343 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
2018-12-17 17:30:49.396 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
2018-12-17 17:30:49.889 [http-nio-6765-exec-10] DEBUG o.a.h.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
2018-12-17 17:30:49.917 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:hadoop (auth:SIMPLE) from:org.apache.hadoop.fs.FileSystem.get(FileSystem.java:210)
2018-12-17 17:30:50.910 [http-nio-6765-exec-10] DEBUG org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
2018-12-17 17:30:51.030 [http-nio-6765-exec-10] DEBUG org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
2018-12-17 17:30:51.058 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - Loading filesystems
2018-12-17 17:30:51.649 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:51.880 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:51.995 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:52.067 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:52.156 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:52.206 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-common/2.9.1/hadoop-common-2.9.1.jar
2018-12-17 17:30:52.635 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:31:00.015 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:31:00.073 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:31:00.207 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - hftp:// = class org.apache.hadoop.hdfs.web.HftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:31:00.268 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - hsftp:// = class org.apache.hadoop.hdfs.web.HsftpFileSystem from /D:/maven-repo/org/apache/hadoop/hadoop-hdfs-client/2.9.1/hadoop-hdfs-client-2.9.1.jar
2018-12-17 17:31:00.274 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
2018-12-17 17:31:00.279 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
2018-12-17 17:31:01.615 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
2018-12-17 17:31:01.619 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
2018-12-17 17:31:05.690 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
2018-12-17 17:31:05.694 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
2018-12-17 17:31:05.698 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
2018-12-17 17:31:05.702 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = 
2018-12-17 17:31:06.106 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2018-12-17 17:31:08.542 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
2018-12-17 17:31:08.766 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
2018-12-17 17:31:11.667 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
2018-12-17 17:31:11.773 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
2018-12-17 17:31:11.793 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
2018-12-17 17:31:11.818 [http-nio-6765-exec-10] DEBUG o.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
2018-12-17 17:31:11.822 [http-nio-6765-exec-10] DEBUG o.a.h.s.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2018-12-17 17:31:13.131 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2018-12-17 17:31:13.704 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@486fb557
2018-12-17 17:31:13.870 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@31cd688a
2018-12-17 17:31:30.370 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
2018-12-17 17:31:30.590 [http-nio-6765-exec-10] DEBUG o.a.h.h.p.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
2018-12-17 17:31:37.649 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DFSClient - /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls: masked=rw-r--r--
2018-12-17 17:31:39.408 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
2018-12-17 17:31:39.455 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.Client - Connecting to /192.168.2.199:8020
2018-12-17 17:31:39.820 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop: starting, having connections 1
2018-12-17 17:31:39.851 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create
2018-12-17 17:31:39.907 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #0
2018-12-17 17:31:39.908 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 1210ms
2018-12-17 17:31:40.621 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls, chunkSize=516, chunksPerPacket=126, packetSize=65016
2018-12-17 17:31:40.853 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_153661207_36] with renew id 1 started
2018-12-17 17:31:42.160 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
2018-12-17 17:31:42.652 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient flush():  bytesCurBlock=21504, lastFlushOffset=0, createNewBlock=false
2018-12-17 17:31:42.657 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 0
2018-12-17 17:31:42.660 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Allocating new block
2018-12-17 17:31:42.661 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DataStreamer - Waiting for ack for: 0
2018-12-17 17:31:42.699 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #1 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock
2018-12-17 17:31:42.843 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #1
2018-12-17 17:31:42.843 [Thread-11] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 145ms
2018-12-17 17:31:42.853 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - pipeline = [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]]
2018-12-17 17:31:42.853 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Connecting to datanode 192.168.2.199:50010
2018-12-17 17:31:42.861 [Thread-11] DEBUG org.apache.hadoop.hdfs.DataStreamer - Send buf size 65536
2018-12-17 17:31:42.861 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #2 org.apache.hadoop.hdfs.protocol.ClientProtocol.getServerDefaults
2018-12-17 17:31:42.965 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #2
2018-12-17 17:31:42.965 [Thread-11] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 104ms
2018-12-17 17:31:42.985 [Thread-11] DEBUG o.a.h.h.p.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /192.168.2.199, datanodeId = DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]
2018-12-17 17:31:43.286 [DataStreamer for file /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - nodes [DatanodeInfoWithStorage[192.168.2.199:50010,DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c,DISK]] storageTypes [DISK] storageIDs [DS-9cd210d7-7185-43aa-aba7-be9b9b43a92c]
2018-12-17 17:31:43.297 [DataStreamer for file /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 21504
2018-12-17 17:31:43.511 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 17:31:43.692 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #3 org.apache.hadoop.hdfs.protocol.ClientProtocol.fsync
2018-12-17 17:31:43.806 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #3
2018-12-17 17:31:43.806 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: fsync took 118ms
2018-12-17 17:31:45.708 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DataStreamer - Queued packet 1
2018-12-17 17:31:45.708 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.hdfs.DataStreamer - Waiting for ack for: 1
2018-12-17 17:31:45.709 [DataStreamer for file /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - DataStreamer block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003 sending packet packet seqno: 1 offsetInBlock: 21504 lastPacketInBlock: true lastByteOffsetInBlock: 21504
2018-12-17 17:31:45.724 [ResponseProcessor for block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2018-12-17 17:31:45.724 [DataStreamer for file /user/hadoop/周工作总结及下周计划（蒋亚球-2018年6月22日).xls block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003] DEBUG org.apache.hadoop.hdfs.DataStreamer - Closing old block BP-776011292-192.168.5.199-1544757847053:blk_1073741827_1003
2018-12-17 17:31:45.727 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #4 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
2018-12-17 17:31:45.767 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #4
2018-12-17 17:31:45.768 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 42ms
2018-12-17 17:31:46.173 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop sending #5 org.apache.hadoop.hdfs.protocol.ClientProtocol.complete
2018-12-17 17:31:46.219 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop got value #5
2018-12-17 17:31:46.219 [http-nio-6765-exec-10] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 46ms
2018-12-17 17:31:56.174 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop: closed
2018-12-17 17:31:56.174 [IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop] DEBUG org.apache.hadoop.ipc.Client - IPC Client (325611580) connection to /192.168.2.199:8020 from hadoop: stopped, remaining connections 0
2018-12-17 17:32:10.870 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 17:32:40.884 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 executed
2018-12-17 17:32:46.887 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 expired
2018-12-17 17:32:46.888 [LeaseRenewer:hadoop@192.168.2.199:8020] DEBUG org.apache.hadoop.hdfs.client.impl.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
